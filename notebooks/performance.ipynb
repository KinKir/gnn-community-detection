{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import dgl.function as fn\n",
    "from dgl import DGLGraph\n",
    "from dgl.data import citation_graph as citegrh\n",
    "\n",
    "# pytorch\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "from math import log\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "\n",
    "from sklearn import metrics as skmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading CORA\n",
    "data = citegrh.load_cora()\n",
    "features = th.FloatTensor(data.features)\n",
    "labels = th.LongTensor(data.labels)\n",
    "mask = th.ByteTensor(data.train_mask)\n",
    "g = data.graph\n",
    "logp = th.rand(size=(labels.shape[0],7))\n",
    "logp_ls = F.log_softmax(logp,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-1.7600, -1.8982, -1.7362,  ..., -2.0066, -1.7634, -2.3472],\n        [-1.7248, -2.1782, -1.9963,  ..., -2.1172, -1.7488, -1.7006],\n        [-2.1764, -1.6801, -2.2152,  ..., -1.5862, -1.8226, -2.2140],\n        ...,\n        [-1.9556, -2.2637, -2.2834,  ..., -1.5916, -1.7782, -2.4438],\n        [-1.6784, -1.9707, -1.6544,  ..., -1.9837, -1.9229, -2.4820],\n        [-1.8556, -2.1586, -2.0655,  ..., -1.5751, -1.7178, -2.1172]])"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logp_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 2, 2, 0, 1], dtype=int64)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = th.LongTensor(np.random.choice(range(3),size=5,p=[1/3,1/3,1/3]))\n",
    "labels = labels.numpy()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(3)[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([[0.3540, 0.1981, 0.4479],\n        [0.4100, 0.2337, 0.3563],\n        [0.3765, 0.4116, 0.2120],\n        [0.1791, 0.3970, 0.4239],\n        [0.2602, 0.3684, 0.3714]])\n[2 0 1 2 2]\n"
    }
   ],
   "source": [
    "logp = th.rand(size=(5,3))\n",
    "logp_ls = F.log_softmax(logp,1)\n",
    "print(F.softmax(logp,1))\n",
    "preds = np.argmax(logp.numpy(),axis=1)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([0.9687, 1.3232, 1.0844, 1.2152, 1.2067, 0.9830])\n"
    },
    {
     "data": {
      "text/plain": "tensor(0.9687)"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perms = list(itertools.permutations(np.unique(labels)))\n",
    "scores = th.tensor([F.nll_loss(logp_ls[:,p], labels) for p in perms])\n",
    "print(scores)\n",
    "th.min(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_score(labels,preds):\n",
    "    return skmetrics.adjusted_rand_score(labels,preds)\n",
    "\n",
    "def mutual_info_score(labels,preds):\n",
    "    return skmetrics.adjusted_mutual_info_score(labels, preds, average_method=\"arithmetic\")\n",
    "\n",
    "def variation_of_information_score(labels,preds):\n",
    "    def mi(x,y):\n",
    "        contingency = skmetrics.cluster.contingency_matrix(x, y, sparse=True)\n",
    "        #print(contingency.todense())\n",
    "        nzx, nzy, nz_val = sp.find(contingency)\n",
    "        contingency_sum = contingency.sum()\n",
    "\n",
    "        pi = np.ravel(contingency.sum(axis=1))\n",
    "        pj = np.ravel(contingency.sum(axis=0))\n",
    "        #print(nz_val)\n",
    "        log_contingency_nm = np.log(nz_val)\n",
    "        #print(log_contingency_nm)\n",
    "        contingency_nm = nz_val / contingency_sum\n",
    "        #print(contingency_nm)\n",
    "\n",
    "        # Don't need to calculate the full outer product, just for non-zeroes\n",
    "        outer = (pi.take(nzx).astype(np.int64, copy=False)\n",
    "                * pj.take(nzy).astype(np.int64, copy=False))\n",
    "        #print(outer)\n",
    "        log_outer = -np.log(outer) + log(pi.sum()) + log(pj.sum())\n",
    "        #print(log_outer)\n",
    "        mi = (contingency_nm * (log_contingency_nm - log(contingency_sum)) + contingency_nm * log_outer)\n",
    "        #print(mi)\n",
    "        return mi.sum()\n",
    "    return mi(labels,labels) + mi(preds,preds) - 2 * mi(labels,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[1 2 2 0 1]\n[2 0 1 2 2]\n\n0.2105263157894737\n0.25177471661855355\n0.6591673732008663\n"
    }
   ],
   "source": [
    "print(labels)\n",
    "print(preds)\n",
    "print(\"\")\n",
    "\n",
    "print(rand_score(labels,preds))\n",
    "print(mutual_info_score(labels,preds))\n",
    "print(variation_of_information_score(labels,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_performance(labels,logits,mask):\n",
    "    logits = logits.detach().numpy()\n",
    "    preds = np.argmax(logits,axis=1)\n",
    "    labels = labels.numpy()\n",
    "    mask = mask.numpy().astype(bool)\n",
    "    pred_sets = {\"All \":preds,\"Train\":preds[mask],\"Test\":preds[np.invert(mask)]}\n",
    "    label_sets = {\"All \":labels,\"Train\":labels[mask],\"Test\":labels[np.invert(mask)]}\n",
    "    eval_functions = {\n",
    "        \"Rand-Index\": rand_score,\n",
    "        \"Mutual Information\": mutual_info_score,\n",
    "        \"Variation of Information\": variation_of_information_score}\n",
    "    scores = {subset: {name: func(label_sets[subset], pred_sets[subset]) for name,func in eval_functions.items()} for subset in pred_sets.keys()}\n",
    "    return scores\n",
    "\n",
    "def print_performance(labels,logits,mask):\n",
    "    scores = compute_performance(labels,logits,mask)\n",
    "    for subset_n, data in scores.items():\n",
    "        eval_message = f\"\\n{subset_n}:\\n\"\n",
    "        for func, score in data.items():\n",
    "            eval_message += f\" {func}: {score:.4f} |\"\n",
    "        print(eval_message)\n",
    "\n",
    "def performance_as_df(labels,logits,mask):\n",
    "    scores = compute_performance(labels,logits,mask)\n",
    "    return pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>All</th>\n      <th>Train</th>\n      <th>Test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Mutual Information</th>\n      <td>0.000850</td>\n      <td>-0.020248</td>\n      <td>0.001165</td>\n    </tr>\n    <tr>\n      <th>Rand-Index</th>\n      <td>0.000440</td>\n      <td>-0.015048</td>\n      <td>0.000489</td>\n    </tr>\n    <tr>\n      <th>Variation of Information</th>\n      <td>3.759567</td>\n      <td>3.506337</td>\n      <td>3.755451</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                              All      Train      Test\nMutual Information        0.000850 -0.020248  0.001165\nRand-Index                0.000440 -0.015048  0.000489\nVariation of Information  3.759567  3.506337  3.755451"
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_as_df(labels,logp_ls,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "class perm_inv_loss:\n",
    "    def __init__(self, labels):\n",
    "        self.labels = labels\n",
    "        self.num_classes = len(labels.unique())\n",
    "        self.label_perms = {i: None for i in range(2,self.num_classes+1)}\n",
    "\n",
    "    def compute_loss(self,logits,mask):\n",
    "        if self.label_perms[self.num_classes] is None:\n",
    "            self.label_perms[self.num_classes] = list(itertools.permutations(np.unique(labels)))\n",
    "\n",
    "        loss = th.tensor(np.infty,requires_grad=True)\n",
    "        for p in self.label_perms:\n",
    "            loss = th.min(loss,F.nll_loss(logits[mask][:,p], labels[mask]))\n",
    "        return loss\n",
    "\n",
    "    def approximate_loss(self,logits,mask,nclasses=3):\n",
    "        if self.label_perms[nclasses] is None:\n",
    "            self.label_perms[nclasses] = list(itertools.permutations(range(nclasses)))\n",
    "\n",
    "        # randomly assign labels to new clusters (trying to roughly achieve equal distribution)\n",
    "        assignments = np.random.choice([i % nclasses for i in range(self.num_classes)],size=self.num_classes,replace=False)\n",
    "        new_labels = th.LongTensor(assignments[self.labels])\n",
    "        one_hot_assignments = th.ByteTensor(np.eye(np.max(assignments) + 1)[assignments])\n",
    "        tensors = [th.sum(logits[:,one_hot_assignments[:,i]],dim=1) for i in range(nclasses)]\n",
    "        new_logits = th.stack(tensors,1)\n",
    "        new_label_perms = list(itertools.permutations(np.unique(new_labels)))\n",
    "        loss = th.tensor(np.infty,requires_grad=True)\n",
    "        for p in new_label_perms:\n",
    "            loss = th.min(loss,F.nll_loss(new_logits[mask][:,p], new_labels[mask]))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([2, 5, 4,  ..., 1, 0, 2])\ntensor(1.9293, grad_fn=<MinBackward2>)\n"
    }
   ],
   "source": [
    "loss1 = perm_inv_loss(labels)\n",
    "print(labels)\n",
    "print(loss1.compute_loss(logp_ls,mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = perm_inv_loss(labels)\n",
    "losstests = {i: {j: loss1.approximate_loss(logp_ls,mask,nclasses=i).detach().numpy() for j in range(50)} for i in range(2,7)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2    0.021068\n3    0.020606\n4    0.035995\n5    0.039213\n6    0.014262\ndtype: float64"
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(losstests).astype(float)\n",
    "res.std()/res.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}