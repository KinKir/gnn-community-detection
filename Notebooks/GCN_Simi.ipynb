{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Convolutional Network by Kipf and Welling"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "\n",
    "import Notebooks.performance as pf\n",
    "\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GNN Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModule(nn.Module):\n",
    "    \"\"\"The linear transformation part of the GCN layer\"\"\"\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(LinearModule, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "        self.activation = activation # This is the activation function\n",
    "\n",
    "    def forward(self, node):\n",
    "        h = self.linear(node.data['h'])\n",
    "        h = self.activation(h)\n",
    "        return {'h' : h}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    \"\"\"A GCN layer\"\"\"\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(GCN, self).__init__()\n",
    "        self.apply_mod = LinearModule(in_feats, out_feats, activation)\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        g.ndata['h'] = feature\n",
    "        g.update_all(message_func=fn.copy_src(src='h', out='m'), reduce_func=fn.sum(msg='m', out='h'))\n",
    "        g.apply_nodes(func=self.apply_mod)\n",
    "        return g.ndata.pop('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, infeats, hidden_size, outfeats):\n",
    "        super(Net, self).__init__()\n",
    "        self.gcn1 = GCN(infeats, hidden_size, F.relu)\n",
    "        self.gcn2 = GCN(hidden_size, hidden_size, F.relu)\n",
    "        self.gcn3 = GCN(hidden_size, outfeats, F.relu)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "\n",
    "    def forward(self, g, features):\n",
    "        x = self.gcn1(g, features)\n",
    "        #x = self.dropout(x)\n",
    "        #x = self.gcn2(g, x)\n",
    "        x = self.gcn3(g, x)\n",
    "        #x = F.log_softmax(x,1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([23262])"
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairg = g.to_networkx()\n",
    "additional_edges = []\n",
    "while len(additional_edges)<10000:\n",
    "    e = (np.random.randint(0,pairg.number_of_nodes()),np.random.randint(0,pairg.number_of_nodes()))\n",
    "    if not (e in pairg.edges): additional_edges.append(e)\n",
    "pairg.add_edges_from(additional_edges)\n",
    "pairsample = (th.LongTensor([i for (i,j) in pairg.edges()]),th.LongTensor([j for (i,j) in pairg.edges()]))\n",
    "pairsample[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_index = th.Tensor(nx.to_numpy_matrix(pairg)).bool().view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairNet(nn.Module):\n",
    "    def __init__(self, infeats, hidden_size, outfeats):\n",
    "        super(PairNet, self).__init__()\n",
    "        self.Net = Net(infeats, hidden_size, outfeats)\n",
    "        self.linear = nn.Linear(outfeats*2, 20)\n",
    "        self.linear2 = nn.Linear(20, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        x = self.Net(g, features)\n",
    "        #x_rep = x.repeat_interleave(x.shape[0],dim=0)\n",
    "        x_rep=th.index_select(x,dim=0,index=pairsample[0])\n",
    "        #y_rep = x.repeat(x.shape[0],1)\n",
    "        y_rep=th.index_select(x,dim=0,index=pairsample[1])\n",
    "        comb = th.cat([x_rep,y_rep],dim=1)\n",
    "        result = self.dropout(comb)\n",
    "        result = self.linear(result)\n",
    "        result = F.relu(result)\n",
    "        result = self.dropout(result)\n",
    "        result = self.linear2(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairall(thenet, g, features):\n",
    "        sig = nn.Sigmoid()\n",
    "        x = thenet.Net(g, features)\n",
    "        x_rep = x.repeat_interleave(x.shape[0],dim=0)\n",
    "        y_rep = x.repeat(x.shape[0],1)\n",
    "        comb = th.cat([x_rep,y_rep],dim=1)\n",
    "        result = thenet.linear(comb)\n",
    "        result = F.relu(result)\n",
    "        result = thenet.linear2(result)\n",
    "        result = sig(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([18264, 1])"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = PairNet(features.shape[1], 21, 4)\n",
    "pred = net(g, features)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.5630],\n        [0.5682],\n        [0.5641],\n        ...,\n        [0.5630],\n        [0.5620],\n        [0.5615]], grad_fn=<SigmoidBackward>)"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.5630, 0.5682, 0.5641,  ..., 0.5683, 0.5673, 0.5668],\n        [0.5555, 0.5608, 0.5566,  ..., 0.5608, 0.5598, 0.5593],\n        [0.5614, 0.5667, 0.5625,  ..., 0.5668, 0.5657, 0.5652],\n        ...,\n        [0.5555, 0.5608, 0.5566,  ..., 0.5608, 0.5598, 0.5593],\n        [0.5568, 0.5621, 0.5579,  ..., 0.5621, 0.5611, 0.5606],\n        [0.5577, 0.5630, 0.5588,  ..., 0.5630, 0.5620, 0.5615]],\n       grad_fn=<ViewBackward>)"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.view(features.shape[0],features.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data import citation_graph as citegrh\n",
    "import networkx as nx\n",
    "\n",
    "data = citegrh.load_cora()\n",
    "features = th.FloatTensor(data.features)\n",
    "labels = th.LongTensor(data.labels)\n",
    "mask = th.BoolTensor(data.train_mask)\n",
    "g = data.graph\n",
    "\n",
    "# add self loop\n",
    "g.remove_edges_from(nx.selfloop_edges(g))\n",
    "g = DGLGraph(g)\n",
    "g.add_edges(g.nodes(), g.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([7333264, 1])"
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_1hot = np.eye(np.max(labels.numpy()) + 1)[labels.numpy()]\n",
    "labels_pair=th.FloatTensor(np.dot(labels_1hot,np.transpose(labels_1hot))).view(-1,1)\n",
    "labels_pair.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_train = 0.5\n",
    "\n",
    "with open(\"data/cora_permutation1.pickle\",\"rb\") as f:\n",
    "    perm1 = pickle.load(f)\n",
    "mask = np.zeros(g.number_of_nodes())\n",
    "mask[perm1[range(int(percentage_train*g.number_of_nodes()))]] = 1\n",
    "mask = th.BoolTensor(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = g.in_degrees().float().unsqueeze(1)\n",
    "citeseer_features = citeseer_g.in_degrees().float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=th.cat([features,th.rand(size=(g.number_of_nodes(),1000))],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=th.eye(g.number_of_nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.BCEWithLogitsLoss() #pf.perm_inv_loss(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\dgl\\base.py:25: UserWarning: Currently adjacency_matrix() returns a matrix with destination as rows by default.  In 0.5 the result will have source as rows (i.e. transpose=True)\n  warnings.warn(msg, warn_type)\n"
    },
    {
     "data": {
      "text/plain": "tensor(0.8488)"
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_pair[g.adjacency_matrix().to_dense().bool().view(-1),:].sum()/g.adjacency_matrix().to_dense().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "ch 00559 | Loss 0.5179 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3366\nEpoch 00560 | Loss 0.5194 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00561 | Loss 0.5184 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3366\nEpoch 00562 | Loss 0.5193 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3366\nEpoch 00563 | Loss 0.5191 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3366\nEpoch 00564 | Loss 0.5219 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3366\nEpoch 00565 | Loss 0.5174 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3366\nEpoch 00566 | Loss 0.5200 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3366\nEpoch 00567 | Loss 0.5206 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3366\nEpoch 00568 | Loss 0.5180 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3366\nEpoch 00569 | Loss 0.5184 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3366\nEpoch 00570 | Loss 0.5163 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3366\nEpoch 00571 | Loss 0.5193 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3366\nEpoch 00572 | Loss 0.5181 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00573 | Loss 0.5187 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00574 | Loss 0.5139 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00575 | Loss 0.5188 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00576 | Loss 0.5157 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00577 | Loss 0.5136 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00578 | Loss 0.5183 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00579 | Loss 0.5180 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00580 | Loss 0.5136 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00581 | Loss 0.5168 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00582 | Loss 0.5155 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00583 | Loss 0.5160 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00584 | Loss 0.5130 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3366\nEpoch 00585 | Loss 0.5179 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3366\nEpoch 00586 | Loss 0.5186 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00587 | Loss 0.5175 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00588 | Loss 0.5156 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00589 | Loss 0.5149 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00590 | Loss 0.5165 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00591 | Loss 0.5147 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00592 | Loss 0.5157 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00593 | Loss 0.5160 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00594 | Loss 0.5125 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00595 | Loss 0.5146 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00596 | Loss 0.5121 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00597 | Loss 0.5171 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00598 | Loss 0.5180 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00599 | Loss 0.5134 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00600 | Loss 0.5158 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00601 | Loss 0.5143 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00602 | Loss 0.5192 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00603 | Loss 0.5210 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00604 | Loss 0.5193 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00605 | Loss 0.5151 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00606 | Loss 0.5192 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00607 | Loss 0.5192 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00608 | Loss 0.5193 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00609 | Loss 0.5174 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00610 | Loss 0.5151 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00611 | Loss 0.5183 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00612 | Loss 0.5184 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00613 | Loss 0.5169 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00614 | Loss 0.5163 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00615 | Loss 0.5184 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00616 | Loss 0.5163 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00617 | Loss 0.5154 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00618 | Loss 0.5133 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00619 | Loss 0.5169 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00620 | Loss 0.5148 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00621 | Loss 0.5150 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00622 | Loss 0.5157 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00623 | Loss 0.5163 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00624 | Loss 0.5144 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00625 | Loss 0.5157 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00626 | Loss 0.5117 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00627 | Loss 0.5139 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00628 | Loss 0.5147 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00629 | Loss 0.5150 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00630 | Loss 0.5130 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00631 | Loss 0.5164 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00632 | Loss 0.5183 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00633 | Loss 0.5150 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00634 | Loss 0.5126 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00635 | Loss 0.5116 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00636 | Loss 0.5134 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00637 | Loss 0.5141 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00638 | Loss 0.5140 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00639 | Loss 0.5152 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00640 | Loss 0.5144 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00641 | Loss 0.5166 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00642 | Loss 0.5164 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00643 | Loss 0.5166 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00644 | Loss 0.5150 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00645 | Loss 0.5126 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00646 | Loss 0.5136 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00647 | Loss 0.5134 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00648 | Loss 0.5146 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00649 | Loss 0.5111 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00650 | Loss 0.5156 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00651 | Loss 0.5087 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00652 | Loss 0.5114 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00653 | Loss 0.5108 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00654 | Loss 0.5118 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00655 | Loss 0.5129 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00656 | Loss 0.5121 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00657 | Loss 0.5111 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00658 | Loss 0.5106 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00659 | Loss 0.5129 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00660 | Loss 0.5131 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00661 | Loss 0.5104 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00662 | Loss 0.5100 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00663 | Loss 0.5102 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00664 | Loss 0.5085 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00665 | Loss 0.5077 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00666 | Loss 0.5108 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00667 | Loss 0.5106 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00668 | Loss 0.5101 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00669 | Loss 0.5123 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00670 | Loss 0.5200 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00671 | Loss 0.5176 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00672 | Loss 0.5105 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00673 | Loss 0.5149 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00674 | Loss 0.5128 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00675 | Loss 0.5139 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00676 | Loss 0.5117 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00677 | Loss 0.5089 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00678 | Loss 0.5081 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00679 | Loss 0.5146 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00680 | Loss 0.5120 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00681 | Loss 0.5086 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00682 | Loss 0.5068 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00683 | Loss 0.5096 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00684 | Loss 0.5075 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00685 | Loss 0.5084 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00686 | Loss 0.5064 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00687 | Loss 0.5088 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00688 | Loss 0.5109 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00689 | Loss 0.5086 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00690 | Loss 0.5083 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00691 | Loss 0.5076 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00692 | Loss 0.5101 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00693 | Loss 0.5079 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00694 | Loss 0.5096 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00695 | Loss 0.5128 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00696 | Loss 0.5055 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00697 | Loss 0.5073 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00698 | Loss 0.5136 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00699 | Loss 0.5077 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00700 | Loss 0.5073 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00701 | Loss 0.5114 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00702 | Loss 0.5102 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00703 | Loss 0.5080 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00704 | Loss 0.5142 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00705 | Loss 0.5083 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00706 | Loss 0.5107 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00707 | Loss 0.5117 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00708 | Loss 0.5117 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00709 | Loss 0.5130 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00710 | Loss 0.5118 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00711 | Loss 0.5176 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00712 | Loss 0.5148 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00713 | Loss 0.5097 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00714 | Loss 0.5138 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00715 | Loss 0.5146 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00716 | Loss 0.5098 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00717 | Loss 0.5139 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00718 | Loss 0.5172 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00719 | Loss 0.5103 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00720 | Loss 0.5105 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3365\nEpoch 00721 | Loss 0.5114 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00722 | Loss 0.5153 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00723 | Loss 0.5087 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00724 | Loss 0.5156 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00725 | Loss 0.5103 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00726 | Loss 0.5161 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00727 | Loss 0.5074 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00728 | Loss 0.5147 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00729 | Loss 0.5097 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00730 | Loss 0.5108 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00731 | Loss 0.5068 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00732 | Loss 0.5114 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00733 | Loss 0.5098 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00734 | Loss 0.5073 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00735 | Loss 0.5102 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00736 | Loss 0.5076 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00737 | Loss 0.5103 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00738 | Loss 0.5091 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00739 | Loss 0.5107 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3364\nEpoch 00740 | Loss 0.5098 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00741 | Loss 0.5103 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00742 | Loss 0.5113 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00743 | Loss 0.5117 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00744 | Loss 0.5094 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00745 | Loss 0.5074 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00746 | Loss 0.5050 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00747 | Loss 0.5089 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00748 | Loss 0.5080 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00749 | Loss 0.5093 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00750 | Loss 0.5051 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00751 | Loss 0.5072 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00752 | Loss 0.5072 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00753 | Loss 0.5071 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00754 | Loss 0.5067 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00755 | Loss 0.5055 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00756 | Loss 0.5078 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00757 | Loss 0.5079 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00758 | Loss 0.5041 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00759 | Loss 0.5050 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00760 | Loss 0.5056 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00761 | Loss 0.5031 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00762 | Loss 0.5091 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00763 | Loss 0.5073 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00764 | Loss 0.5042 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00765 | Loss 0.5046 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00766 | Loss 0.5060 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00767 | Loss 0.5058 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00768 | Loss 0.5051 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00769 | Loss 0.5065 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00770 | Loss 0.5069 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00771 | Loss 0.5052 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00772 | Loss 0.5055 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00773 | Loss 0.5026 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00774 | Loss 0.5027 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00775 | Loss 0.5021 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00776 | Loss 0.5084 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00777 | Loss 0.5080 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00778 | Loss 0.5055 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00779 | Loss 0.5086 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00780 | Loss 0.5077 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00781 | Loss 0.5099 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00782 | Loss 0.5048 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00783 | Loss 0.5094 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00784 | Loss 0.5071 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00785 | Loss 0.5106 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00786 | Loss 0.5090 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00787 | Loss 0.5078 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00788 | Loss 0.5057 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00789 | Loss 0.5120 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00790 | Loss 0.5066 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00791 | Loss 0.5082 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00792 | Loss 0.5068 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00793 | Loss 0.5091 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00794 | Loss 0.5062 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00795 | Loss 0.5063 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3362\nEpoch 00796 | Loss 0.5075 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00797 | Loss 0.5061 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00798 | Loss 0.5040 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\nEpoch 00799 | Loss 0.5090 | Train.Rand 0.0000 | Valid.Rand 0.0000 | Time(s) 0.3363\n"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "net = PairNet(features.shape[1], 21, 21)\n",
    "#print(net)\n",
    "\n",
    "optimizer = th.optim.Adam(net.parameters(), lr=1e-2, weight_decay=0)\n",
    "net.train() # Set to training mode (use dropout)\n",
    "\n",
    "dur = []\n",
    "for epoch in range(800):\n",
    "    if epoch >=3:\n",
    "        t0 = time.time()\n",
    "\n",
    "    # Compute loss for test nodes (only for validation, not used by optimizer)\n",
    "    #net.eval()\n",
    "    #prediction = net(g, features)\n",
    "    #train_rand=pf.rand_score(labels[mask].numpy(),np.argmax(prediction[mask].detach().numpy(), axis=1))\n",
    "    #validation_rand=pf.rand_score(labels[~mask].numpy(),np.argmax(prediction[~mask].detach().numpy(), axis=1))\n",
    "    train_rand=0\n",
    "    validation_rand=0\n",
    "    #net.train()\n",
    "\n",
    "    # Compute loss for train nodes\n",
    "    prediction = net(g, features)\n",
    "\n",
    "    #loss = loss_function.approximate_loss(logits,mask,nclasses=3)\n",
    "    \n",
    "    #loss = F.nll_loss(logits[mask], labels[mask])\n",
    "    loss = loss_function(prediction,labels_pair[adj_index,:])\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch >=3:\n",
    "        dur.append(time.time() - t0)\n",
    "        print(f\"Epoch {epoch:05d} | Loss {loss.item():.4f} | Train.Rand {train_rand:.4f} | Valid.Rand {validation_rand:.4f} | Time(s) {np.mean(dur):.4f}\")\n",
    "    else:\n",
    "        print(f\"Epoch {epoch:05d} | Loss {loss.item():.4f} | Train.Rand {train_rand:.4f} | Valid.Rand {validation_rand:.4f} | Time(s) unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.4760, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()\n",
    "final_prediction = np.round(pairall(net, g, features).detach().view(g.number_of_nodes(),g.number_of_nodes()))\n",
    "loss_function(net(g, features),labels_pair[adj_index,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.6637)"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_pair[adj_index,:].sum()/labels_pair[adj_index,:].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Percentage of links in complete graph. Predicted: 0.5108 | Real: 0.1796\n"
    }
   ],
   "source": [
    "\n",
    "print(f\"Percentage of links in complete graph. Predicted: {(final_prediction.sum()/(g.number_of_nodes()**2)).item():.4f} | Real: {(labels_pair.sum()/(g.number_of_nodes()**2)).item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n        [1., 1., 1.,  ..., 1., 1., 1.],\n        [1., 1., 1.,  ..., 1., 1., 1.],\n        ...,\n        [1., 1., 1.,  ..., 1., 1., 1.],\n        [1., 1., 1.,  ..., 1., 1., 1.],\n        [1., 1., 1.,  ..., 1., 1., 1.]])"
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction=labels_pair.view(2708,2708)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use connected components of similarity graph where bridgy links have been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dissimmat(final_prediction):\n",
    "    dissims = {(i,j): distance.jaccard(f1,f2) for i,f1 in enumerate(final_prediction) for j,f2 in enumerate(final_prediction) if j>=i}\n",
    "    diss_matrix=np.array([[dissims[(i,j)] if (i,j) in dissims else dissims[(j,i)] for j in range(final_prediction.shape[0])] for i in range(final_prediction.shape[0])])\n",
    "    return diss_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "dissmat = dissimmat(final_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "7\n"
    }
   ],
   "source": [
    "compG = nx.from_numpy_matrix(dissmat<0.2,create_using=nx.Graph())\n",
    "print(nx.number_connected_components(compG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute labels out of connected components\n",
    "pred_labels = np.zeros(2708)\n",
    "for i,c in enumerate(nx.connected_components(compG)):\n",
    "    pred_labels[list(c)] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.020572259069134742"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.rand_score(labels,pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "    return np.allclose(a, a.T, rtol=rtol, atol=atol)\n",
    "check_symmetric(final_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>All</th>\n      <th>Train</th>\n      <th>Test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Rand-Index</td>\n      <td>0.779452</td>\n      <td>0.982582</td>\n      <td>0.596059</td>\n    </tr>\n    <tr>\n      <td>Mutual Information</td>\n      <td>0.749836</td>\n      <td>0.974923</td>\n      <td>0.592846</td>\n    </tr>\n    <tr>\n      <td>Variation of Information</td>\n      <td>0.906211</td>\n      <td>0.089857</td>\n      <td>1.474745</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                              All      Train      Test\nRand-Index                0.779452  0.982582  0.596059\nMutual Information        0.749836  0.974923  0.592846\nVariation of Information  0.906211  0.089857  1.474745"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval() # Set net to evaluation mode (deactivates dropout)\n",
    "final_prediction = net(g, features).detach()\n",
    "pf.performance_as_df(labels,final_prediction,mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval() # Set net to evaluation mode (deactivates dropout)\n",
    "sigf = nn.Sigmoid()\n",
    "#final_prediction = np.round(sigf(net(g, features)).detach())\n",
    "# change shape\n",
    "final_prediction = final_prediction.view(g.number_of_nodes(),g.number_of_nodes()).numpy()\n",
    "#final_prediction = labels_pair.view(g.number_of_nodes(),g.number_of_nodes()).numpy()\n",
    "#final_prediction = graphmatrix.view(g.number_of_nodes(),g.number_of_nodes()).numpy()\n",
    "compG = nx.from_numpy_matrix(final_prediction,create_using=nx.Graph())\n",
    "\n",
    "def neighborhood_overlap(g, u, v):\n",
    "    n_common_nbrs = len(set(nx.common_neighbors(g, u, v)))\n",
    "    n_join_nbrs = g.degree(u) + g.degree(v) - n_common_nbrs - 2\n",
    "    return n_common_nbrs / n_join_nbrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1\n"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-498-c5f3de05cb5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber_connected_components\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbridge_like\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcompG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mneighborhood_overlap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbridge_like\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#compG.remove_edges_from(bridge_like)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#print(nx.number_connected_components(compG))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-498-c5f3de05cb5e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber_connected_components\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbridge_like\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcompG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mneighborhood_overlap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbridge_like\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#compG.remove_edges_from(bridge_like)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#print(nx.number_connected_components(compG))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-495-56ff62906407>\u001b[0m in \u001b[0;36mneighborhood_overlap\u001b[1;34m(g, u, v)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mneighborhood_overlap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mn_common_nbrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon_neighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mn_join_nbrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_common_nbrs\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mn_common_nbrs\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn_join_nbrs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\networkx\\classes\\function.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    936\u001b[0m     \u001b[1;31m# Return a generator explicitly instead of yielding so that the above\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m     \u001b[1;31m# checks are executed eagerly.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 938\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(nx.number_connected_components(compG))\n",
    "bridge_like = [(u,v) for (u,v) in compG.edges() if neighborhood_overlap(compG, u, v)<0.9]\n",
    "print(bridge_like)\n",
    "#compG.remove_edges_from(bridge_like)\n",
    "#print(nx.number_connected_components(compG))"
   ]
  }
 ]
}