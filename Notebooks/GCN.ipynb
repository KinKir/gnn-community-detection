{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Convolutional Network by Kipf and Welling"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "\n",
    "import Notebooks.performance as pf"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GNN Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModule(nn.Module):\n",
    "    \"\"\"The linear transformation part of the GCN layer\"\"\"\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(LinearModule, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "        self.activation = activation # This is the activation function\n",
    "\n",
    "    def forward(self, node):\n",
    "        h = self.linear(node.data['h'])\n",
    "        h = self.activation(h)\n",
    "        return {'h' : h}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    \"\"\"A GCN layer\"\"\"\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(GCN, self).__init__()\n",
    "        self.apply_mod = LinearModule(in_feats, out_feats, activation)\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        g.ndata['h'] = feature\n",
    "        g.update_all(message_func=fn.copy_src(src='h', out='m'), reduce_func=fn.sum(msg='m', out='h'))\n",
    "        g.apply_nodes(func=self.apply_mod)\n",
    "        return g.ndata.pop('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, infeats, hidden_size, outfeats):\n",
    "        super(Net, self).__init__()\n",
    "        self.gcn1 = GCN(infeats, hidden_size, F.relu)\n",
    "        self.gcn2 = GCN(hidden_size, outfeats, lambda x: F.log_softmax(x,1))\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        x = self.gcn1(g, features)\n",
    "        #x = self.dropout(x)\n",
    "        x = self.gcn2(g, x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data import citation_graph as citegrh\n",
    "import networkx as nx\n",
    "\n",
    "data = citegrh.load_cora()\n",
    "features = th.FloatTensor(data.features)\n",
    "labels = th.LongTensor(data.labels)\n",
    "mask = th.ByteTensor(data.train_mask)\n",
    "g = data.graph\n",
    "\n",
    "# add self loop\n",
    "g.remove_edges_from(nx.selfloop_edges(g))\n",
    "g = DGLGraph(g)\n",
    "g.add_edges(g.nodes(), g.nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_train = 0.02\n",
    "\n",
    "with open(\"data/cora_permutation1.pickle\",\"rb\") as f:\n",
    "    perm1 = pickle.load(f)\n",
    "mask = np.zeros(g.number_of_nodes())\n",
    "mask[perm1[range(int(percentage_train*g.number_of_nodes()))]] = 1\n",
    "mask = th.ByteTensor(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = pf.perm_inv_loss(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Rand 0.1258 | Time(s) 0.2378\nEpoch 00174 | Loss 1.9274 | Valid.Rand 0.1275 | Time(s) 0.2377\nEpoch 00175 | Loss 1.9972 | Valid.Rand 0.1260 | Time(s) 0.2379\nEpoch 00176 | Loss 1.8619 | Valid.Rand 0.1265 | Time(s) 0.2377\nEpoch 00177 | Loss 1.8887 | Valid.Rand 0.1266 | Time(s) 0.2375\nEpoch 00178 | Loss 2.1493 | Valid.Rand 0.1265 | Time(s) 0.2379\nEpoch 00179 | Loss 2.0027 | Valid.Rand 0.1258 | Time(s) 0.2377\nEpoch 00180 | Loss 1.9271 | Valid.Rand 0.1267 | Time(s) 0.2375\nEpoch 00181 | Loss 2.3715 | Valid.Rand 0.1275 | Time(s) 0.2377\nEpoch 00182 | Loss 1.9558 | Valid.Rand 0.1299 | Time(s) 0.2377\nEpoch 00183 | Loss 2.3489 | Valid.Rand 0.1297 | Time(s) 0.2375\nEpoch 00184 | Loss 2.1020 | Valid.Rand 0.1288 | Time(s) 0.2374\nEpoch 00185 | Loss 1.8529 | Valid.Rand 0.1274 | Time(s) 0.2375\nEpoch 00186 | Loss 2.0363 | Valid.Rand 0.1241 | Time(s) 0.2374\nEpoch 00187 | Loss 1.9734 | Valid.Rand 0.1247 | Time(s) 0.2373\nEpoch 00188 | Loss 2.1425 | Valid.Rand 0.1264 | Time(s) 0.2376\nEpoch 00189 | Loss 2.1634 | Valid.Rand 0.1248 | Time(s) 0.2375\nEpoch 00190 | Loss 1.9887 | Valid.Rand 0.1234 | Time(s) 0.2374\nEpoch 00191 | Loss 2.1398 | Valid.Rand 0.1228 | Time(s) 0.2378\nEpoch 00192 | Loss 2.0215 | Valid.Rand 0.1227 | Time(s) 0.2377\nEpoch 00193 | Loss 1.9146 | Valid.Rand 0.1206 | Time(s) 0.2378\nEpoch 00194 | Loss 2.1931 | Valid.Rand 0.1187 | Time(s) 0.2381\nEpoch 00195 | Loss 2.4149 | Valid.Rand 0.1159 | Time(s) 0.2380\nEpoch 00196 | Loss 2.0620 | Valid.Rand 0.1173 | Time(s) 0.2379\nEpoch 00197 | Loss 1.8728 | Valid.Rand 0.1193 | Time(s) 0.2378\nEpoch 00198 | Loss 2.3307 | Valid.Rand 0.1164 | Time(s) 0.2376\nEpoch 00199 | Loss 1.9902 | Valid.Rand 0.1179 | Time(s) 0.2379\nEpoch 00200 | Loss 2.3887 | Valid.Rand 0.1227 | Time(s) 0.2378\nEpoch 00201 | Loss 2.0145 | Valid.Rand 0.1233 | Time(s) 0.2377\nEpoch 00202 | Loss 1.8977 | Valid.Rand 0.1253 | Time(s) 0.2377\nEpoch 00203 | Loss 1.9569 | Valid.Rand 0.1239 | Time(s) 0.2378\nEpoch 00204 | Loss 2.1266 | Valid.Rand 0.1245 | Time(s) 0.2377\nEpoch 00205 | Loss 1.7465 | Valid.Rand 0.1261 | Time(s) 0.2376\nEpoch 00206 | Loss 2.0586 | Valid.Rand 0.1281 | Time(s) 0.2379\nEpoch 00207 | Loss 2.1174 | Valid.Rand 0.1289 | Time(s) 0.2379\nEpoch 00208 | Loss 1.9546 | Valid.Rand 0.1320 | Time(s) 0.2377\nEpoch 00209 | Loss 2.1112 | Valid.Rand 0.1319 | Time(s) 0.2378\nEpoch 00210 | Loss 1.9355 | Valid.Rand 0.1354 | Time(s) 0.2377\nEpoch 00211 | Loss 2.1262 | Valid.Rand 0.1394 | Time(s) 0.2376\nEpoch 00212 | Loss 2.2961 | Valid.Rand 0.1432 | Time(s) 0.2375\nEpoch 00213 | Loss 1.8376 | Valid.Rand 0.1467 | Time(s) 0.2374\nEpoch 00214 | Loss 2.3173 | Valid.Rand 0.1509 | Time(s) 0.2373\nEpoch 00215 | Loss 2.1023 | Valid.Rand 0.1569 | Time(s) 0.2372\nEpoch 00216 | Loss 2.0169 | Valid.Rand 0.1647 | Time(s) 0.2376\nEpoch 00217 | Loss 1.8856 | Valid.Rand 0.1671 | Time(s) 0.2375\nEpoch 00218 | Loss 2.2028 | Valid.Rand 0.1680 | Time(s) 0.2375\nEpoch 00219 | Loss 1.9206 | Valid.Rand 0.1708 | Time(s) 0.2375\nEpoch 00220 | Loss 2.4138 | Valid.Rand 0.1736 | Time(s) 0.2374\nEpoch 00221 | Loss 1.8004 | Valid.Rand 0.1720 | Time(s) 0.2373\nEpoch 00222 | Loss 2.1796 | Valid.Rand 0.1722 | Time(s) 0.2373\nEpoch 00223 | Loss 2.0811 | Valid.Rand 0.1713 | Time(s) 0.2372\nEpoch 00224 | Loss 1.9626 | Valid.Rand 0.1728 | Time(s) 0.2370\nEpoch 00225 | Loss 2.4107 | Valid.Rand 0.1698 | Time(s) 0.2373\nEpoch 00226 | Loss 1.7887 | Valid.Rand 0.1678 | Time(s) 0.2372\nEpoch 00227 | Loss 1.9375 | Valid.Rand 0.1670 | Time(s) 0.2375\nEpoch 00228 | Loss 1.8954 | Valid.Rand 0.1659 | Time(s) 0.2376\nEpoch 00229 | Loss 2.0185 | Valid.Rand 0.1579 | Time(s) 0.2375\nEpoch 00230 | Loss 2.0289 | Valid.Rand 0.1519 | Time(s) 0.2376\nEpoch 00231 | Loss 2.0922 | Valid.Rand 0.1528 | Time(s) 0.2375\nEpoch 00232 | Loss 1.8751 | Valid.Rand 0.1483 | Time(s) 0.2376\nEpoch 00233 | Loss 2.1107 | Valid.Rand 0.1404 | Time(s) 0.2377\nEpoch 00234 | Loss 2.2072 | Valid.Rand 0.1316 | Time(s) 0.2376\nEpoch 00235 | Loss 2.0243 | Valid.Rand 0.1240 | Time(s) 0.2378\nEpoch 00236 | Loss 2.0075 | Valid.Rand 0.1168 | Time(s) 0.2378\nEpoch 00237 | Loss 1.8725 | Valid.Rand 0.1111 | Time(s) 0.2377\nEpoch 00238 | Loss 1.9022 | Valid.Rand 0.1076 | Time(s) 0.2376\nEpoch 00239 | Loss 2.2960 | Valid.Rand 0.1050 | Time(s) 0.2375\nEpoch 00240 | Loss 1.8503 | Valid.Rand 0.1038 | Time(s) 0.2373\nEpoch 00241 | Loss 1.9757 | Valid.Rand 0.1014 | Time(s) 0.2378\nEpoch 00242 | Loss 2.0782 | Valid.Rand 0.0999 | Time(s) 0.2379\nEpoch 00243 | Loss 1.8465 | Valid.Rand 0.0990 | Time(s) 0.2377\nEpoch 00244 | Loss 1.8546 | Valid.Rand 0.0976 | Time(s) 0.2376\nEpoch 00245 | Loss 1.7834 | Valid.Rand 0.0974 | Time(s) 0.2375\nEpoch 00246 | Loss 2.1680 | Valid.Rand 0.0948 | Time(s) 0.2377\nEpoch 00247 | Loss 1.9208 | Valid.Rand 0.0942 | Time(s) 0.2376\nEpoch 00248 | Loss 1.7757 | Valid.Rand 0.0959 | Time(s) 0.2376\nEpoch 00249 | Loss 2.1806 | Valid.Rand 0.0970 | Time(s) 0.2376\nEpoch 00250 | Loss 2.2022 | Valid.Rand 0.0977 | Time(s) 0.2376\nEpoch 00251 | Loss 2.0904 | Valid.Rand 0.1004 | Time(s) 0.2379\nEpoch 00252 | Loss 2.1004 | Valid.Rand 0.1009 | Time(s) 0.2378\nEpoch 00253 | Loss 2.2765 | Valid.Rand 0.1043 | Time(s) 0.2378\nEpoch 00254 | Loss 1.9832 | Valid.Rand 0.1066 | Time(s) 0.2379\nEpoch 00255 | Loss 1.9913 | Valid.Rand 0.1082 | Time(s) 0.2378\nEpoch 00256 | Loss 1.8088 | Valid.Rand 0.1121 | Time(s) 0.2379\nEpoch 00257 | Loss 2.0506 | Valid.Rand 0.1143 | Time(s) 0.2378\nEpoch 00258 | Loss 2.1105 | Valid.Rand 0.1144 | Time(s) 0.2378\nEpoch 00259 | Loss 1.8034 | Valid.Rand 0.1164 | Time(s) 0.2382\nEpoch 00260 | Loss 1.8083 | Valid.Rand 0.1174 | Time(s) 0.2381\nEpoch 00261 | Loss 2.3259 | Valid.Rand 0.1208 | Time(s) 0.2382\nEpoch 00262 | Loss 1.8330 | Valid.Rand 0.1194 | Time(s) 0.2381\nEpoch 00263 | Loss 1.8728 | Valid.Rand 0.1184 | Time(s) 0.2380\nEpoch 00264 | Loss 1.9495 | Valid.Rand 0.1225 | Time(s) 0.2379\nEpoch 00265 | Loss 1.9480 | Valid.Rand 0.1267 | Time(s) 0.2378\nEpoch 00266 | Loss 2.2595 | Valid.Rand 0.1274 | Time(s) 0.2380\nEpoch 00267 | Loss 1.8366 | Valid.Rand 0.1275 | Time(s) 0.2380\nEpoch 00268 | Loss 2.2393 | Valid.Rand 0.1258 | Time(s) 0.2380\nEpoch 00269 | Loss 1.7657 | Valid.Rand 0.1291 | Time(s) 0.2380\nEpoch 00270 | Loss 1.8338 | Valid.Rand 0.1325 | Time(s) 0.2379\nEpoch 00271 | Loss 1.9580 | Valid.Rand 0.1389 | Time(s) 0.2378\nEpoch 00272 | Loss 1.8664 | Valid.Rand 0.1434 | Time(s) 0.2378\nEpoch 00273 | Loss 2.2338 | Valid.Rand 0.1472 | Time(s) 0.2377\nEpoch 00274 | Loss 1.7370 | Valid.Rand 0.1492 | Time(s) 0.2379\nEpoch 00275 | Loss 2.1490 | Valid.Rand 0.1489 | Time(s) 0.2378\nEpoch 00276 | Loss 2.1443 | Valid.Rand 0.1498 | Time(s) 0.2378\nEpoch 00277 | Loss 2.0742 | Valid.Rand 0.1504 | Time(s) 0.2376\nEpoch 00278 | Loss 2.0244 | Valid.Rand 0.1481 | Time(s) 0.2377\nEpoch 00279 | Loss 2.4143 | Valid.Rand 0.1466 | Time(s) 0.2378\nEpoch 00280 | Loss 1.8255 | Valid.Rand 0.1392 | Time(s) 0.2378\nEpoch 00281 | Loss 1.8593 | Valid.Rand 0.1301 | Time(s) 0.2379\nEpoch 00282 | Loss 1.8863 | Valid.Rand 0.1267 | Time(s) 0.2378\nEpoch 00283 | Loss 1.7613 | Valid.Rand 0.1250 | Time(s) 0.2378\nEpoch 00284 | Loss 1.8306 | Valid.Rand 0.1280 | Time(s) 0.2377\nEpoch 00285 | Loss 2.0277 | Valid.Rand 0.1278 | Time(s) 0.2379\nEpoch 00286 | Loss 1.9715 | Valid.Rand 0.1301 | Time(s) 0.2378\nEpoch 00287 | Loss 1.9555 | Valid.Rand 0.1303 | Time(s) 0.2377\nEpoch 00288 | Loss 2.3739 | Valid.Rand 0.1311 | Time(s) 0.2377\nEpoch 00289 | Loss 2.3299 | Valid.Rand 0.1355 | Time(s) 0.2378\nEpoch 00290 | Loss 1.8295 | Valid.Rand 0.1378 | Time(s) 0.2377\nEpoch 00291 | Loss 1.7317 | Valid.Rand 0.1380 | Time(s) 0.2376\nEpoch 00292 | Loss 2.2940 | Valid.Rand 0.1432 | Time(s) 0.2378\nEpoch 00293 | Loss 2.0076 | Valid.Rand 0.1462 | Time(s) 0.2378\nEpoch 00294 | Loss 1.8542 | Valid.Rand 0.1510 | Time(s) 0.2377\nEpoch 00295 | Loss 1.9948 | Valid.Rand 0.1543 | Time(s) 0.2376\nEpoch 00296 | Loss 1.9404 | Valid.Rand 0.1567 | Time(s) 0.2376\nEpoch 00297 | Loss 2.1307 | Valid.Rand 0.1633 | Time(s) 0.2375\nEpoch 00298 | Loss 1.8434 | Valid.Rand 0.1701 | Time(s) 0.2377\nEpoch 00299 | Loss 1.9440 | Valid.Rand 0.1719 | Time(s) 0.2377\nEpoch 00300 | Loss 2.2267 | Valid.Rand 0.1759 | Time(s) 0.2379\nEpoch 00301 | Loss 2.0989 | Valid.Rand 0.1758 | Time(s) 0.2379\nEpoch 00302 | Loss 2.1214 | Valid.Rand 0.1767 | Time(s) 0.2379\nEpoch 00303 | Loss 1.8082 | Valid.Rand 0.1805 | Time(s) 0.2378\nEpoch 00304 | Loss 2.2417 | Valid.Rand 0.1805 | Time(s) 0.2378\nEpoch 00305 | Loss 2.1650 | Valid.Rand 0.1808 | Time(s) 0.2379\nEpoch 00306 | Loss 1.8443 | Valid.Rand 0.1818 | Time(s) 0.2378\nEpoch 00307 | Loss 1.7595 | Valid.Rand 0.1818 | Time(s) 0.2377\nEpoch 00308 | Loss 1.9489 | Valid.Rand 0.1817 | Time(s) 0.2379\nEpoch 00309 | Loss 2.1619 | Valid.Rand 0.1809 | Time(s) 0.2381\nEpoch 00310 | Loss 2.0949 | Valid.Rand 0.1800 | Time(s) 0.2382\nEpoch 00311 | Loss 1.7576 | Valid.Rand 0.1808 | Time(s) 0.2383\nEpoch 00312 | Loss 1.9185 | Valid.Rand 0.1803 | Time(s) 0.2384\nEpoch 00313 | Loss 1.9761 | Valid.Rand 0.1793 | Time(s) 0.2383\nEpoch 00314 | Loss 1.8931 | Valid.Rand 0.1802 | Time(s) 0.2384\nEpoch 00315 | Loss 1.9713 | Valid.Rand 0.1813 | Time(s) 0.2383\nEpoch 00316 | Loss 2.1453 | Valid.Rand 0.1823 | Time(s) 0.2383\nEpoch 00317 | Loss 2.2175 | Valid.Rand 0.1807 | Time(s) 0.2384\nEpoch 00318 | Loss 1.9882 | Valid.Rand 0.1831 | Time(s) 0.2383\nEpoch 00319 | Loss 1.9009 | Valid.Rand 0.1849 | Time(s) 0.2383\nEpoch 00320 | Loss 2.2784 | Valid.Rand 0.1868 | Time(s) 0.2383\nEpoch 00321 | Loss 2.1245 | Valid.Rand 0.1886 | Time(s) 0.2383\nEpoch 00322 | Loss 1.9552 | Valid.Rand 0.1881 | Time(s) 0.2383\nEpoch 00323 | Loss 2.2390 | Valid.Rand 0.1866 | Time(s) 0.2386\nEpoch 00324 | Loss 2.0372 | Valid.Rand 0.1887 | Time(s) 0.2386\nEpoch 00325 | Loss 1.9803 | Valid.Rand 0.1879 | Time(s) 0.2385\nEpoch 00326 | Loss 1.9854 | Valid.Rand 0.1776 | Time(s) 0.2384\nEpoch 00327 | Loss 1.9563 | Valid.Rand 0.1730 | Time(s) 0.2384\nEpoch 00328 | Loss 1.8671 | Valid.Rand 0.1664 | Time(s) 0.2383\nEpoch 00329 | Loss 1.8373 | Valid.Rand 0.1629 | Time(s) 0.2382\nEpoch 00330 | Loss 2.0725 | Valid.Rand 0.1596 | Time(s) 0.2382\nEpoch 00331 | Loss 1.7615 | Valid.Rand 0.1567 | Time(s) 0.2382\nEpoch 00332 | Loss 2.4730 | Valid.Rand 0.1542 | Time(s) 0.2381\nEpoch 00333 | Loss 2.1926 | Valid.Rand 0.1528 | Time(s) 0.2384\nEpoch 00334 | Loss 1.9243 | Valid.Rand 0.1533 | Time(s) 0.2383\nEpoch 00335 | Loss 1.8085 | Valid.Rand 0.1521 | Time(s) 0.2384\nEpoch 00336 | Loss 2.0571 | Valid.Rand 0.1511 | Time(s) 0.2384\nEpoch 00337 | Loss 2.0525 | Valid.Rand 0.1506 | Time(s) 0.2384\nEpoch 00338 | Loss 1.8554 | Valid.Rand 0.1509 | Time(s) 0.2384\nEpoch 00339 | Loss 1.8988 | Valid.Rand 0.1550 | Time(s) 0.2384\nEpoch 00340 | Loss 2.0432 | Valid.Rand 0.1572 | Time(s) 0.2384\nEpoch 00341 | Loss 1.9691 | Valid.Rand 0.1590 | Time(s) 0.2383\nEpoch 00342 | Loss 1.7471 | Valid.Rand 0.1564 | Time(s) 0.2383\nEpoch 00343 | Loss 2.0159 | Valid.Rand 0.1569 | Time(s) 0.2383\nEpoch 00344 | Loss 1.9251 | Valid.Rand 0.1569 | Time(s) 0.2382\nEpoch 00345 | Loss 2.2602 | Valid.Rand 0.1554 | Time(s) 0.2382\nEpoch 00346 | Loss 1.9201 | Valid.Rand 0.1539 | Time(s) 0.2381\nEpoch 00347 | Loss 2.0043 | Valid.Rand 0.1511 | Time(s) 0.2382\nEpoch 00348 | Loss 1.8054 | Valid.Rand 0.1484 | Time(s) 0.2383\nEpoch 00349 | Loss 1.7093 | Valid.Rand 0.1482 | Time(s) 0.2382\nEpoch 00350 | Loss 2.3141 | Valid.Rand 0.1472 | Time(s) 0.2383\nEpoch 00351 | Loss 1.9815 | Valid.Rand 0.1482 | Time(s) 0.2383\nEpoch 00352 | Loss 2.0062 | Valid.Rand 0.1523 | Time(s) 0.2382\nEpoch 00353 | Loss 2.1108 | Valid.Rand 0.1533 | Time(s) 0.2383\nEpoch 00354 | Loss 1.6941 | Valid.Rand 0.1537 | Time(s) 0.2383\nEpoch 00355 | Loss 1.9877 | Valid.Rand 0.1528 | Time(s) 0.2382\nEpoch 00356 | Loss 1.8257 | Valid.Rand 0.1552 | Time(s) 0.2381\nEpoch 00357 | Loss 1.5994 | Valid.Rand 0.1580 | Time(s) 0.2382\nEpoch 00358 | Loss 2.0977 | Valid.Rand 0.1614 | Time(s) 0.2383\nEpoch 00359 | Loss 2.2259 | Valid.Rand 0.1623 | Time(s) 0.2383\nEpoch 00360 | Loss 1.9722 | Valid.Rand 0.1601 | Time(s) 0.2383\nEpoch 00361 | Loss 2.0831 | Valid.Rand 0.1598 | Time(s) 0.2383\nEpoch 00362 | Loss 1.9102 | Valid.Rand 0.1615 | Time(s) 0.2383\nEpoch 00363 | Loss 2.1802 | Valid.Rand 0.1620 | Time(s) 0.2383\nEpoch 00364 | Loss 1.6551 | Valid.Rand 0.1618 | Time(s) 0.2385\nEpoch 00365 | Loss 2.1970 | Valid.Rand 0.1618 | Time(s) 0.2385\nEpoch 00366 | Loss 1.9414 | Valid.Rand 0.1625 | Time(s) 0.2385\nEpoch 00367 | Loss 1.7089 | Valid.Rand 0.1621 | Time(s) 0.2385\nEpoch 00368 | Loss 1.8699 | Valid.Rand 0.1626 | Time(s) 0.2384\nEpoch 00369 | Loss 2.0712 | Valid.Rand 0.1632 | Time(s) 0.2384\nEpoch 00370 | Loss 1.9926 | Valid.Rand 0.1635 | Time(s) 0.2385\nEpoch 00371 | Loss 1.5549 | Valid.Rand 0.1632 | Time(s) 0.2384\nEpoch 00372 | Loss 1.9551 | Valid.Rand 0.1622 | Time(s) 0.2385\nEpoch 00373 | Loss 2.1652 | Valid.Rand 0.1625 | Time(s) 0.2384\nEpoch 00374 | Loss 1.6821 | Valid.Rand 0.1617 | Time(s) 0.2384\nEpoch 00375 | Loss 1.8779 | Valid.Rand 0.1631 | Time(s) 0.2383\nEpoch 00376 | Loss 2.1896 | Valid.Rand 0.1636 | Time(s) 0.2383\nEpoch 00377 | Loss 1.9345 | Valid.Rand 0.1655 | Time(s) 0.2385\nEpoch 00378 | Loss 2.1240 | Valid.Rand 0.1712 | Time(s) 0.2385\nEpoch 00379 | Loss 1.6650 | Valid.Rand 0.1840 | Time(s) 0.2385\nEpoch 00380 | Loss 1.9071 | Valid.Rand 0.1910 | Time(s) 0.2384\nEpoch 00381 | Loss 2.2724 | Valid.Rand 0.1942 | Time(s) 0.2384\nEpoch 00382 | Loss 1.9168 | Valid.Rand 0.1951 | Time(s) 0.2383\nEpoch 00383 | Loss 1.9043 | Valid.Rand 0.1960 | Time(s) 0.2383\nEpoch 00384 | Loss 2.0838 | Valid.Rand 0.1979 | Time(s) 0.2383\nEpoch 00385 | Loss 2.2299 | Valid.Rand 0.1977 | Time(s) 0.2383\nEpoch 00386 | Loss 2.0947 | Valid.Rand 0.1855 | Time(s) 0.2383\nEpoch 00387 | Loss 2.0232 | Valid.Rand 0.1773 | Time(s) 0.2382\nEpoch 00388 | Loss 2.2552 | Valid.Rand 0.1705 | Time(s) 0.2383\nEpoch 00389 | Loss 1.9829 | Valid.Rand 0.1683 | Time(s) 0.2382\nEpoch 00390 | Loss 1.9074 | Valid.Rand 0.1673 | Time(s) 0.2382\nEpoch 00391 | Loss 2.0823 | Valid.Rand 0.1706 | Time(s) 0.2381\nEpoch 00392 | Loss 1.8012 | Valid.Rand 0.1694 | Time(s) 0.2381\nEpoch 00393 | Loss 1.9067 | Valid.Rand 0.1720 | Time(s) 0.2381\nEpoch 00394 | Loss 2.1254 | Valid.Rand 0.1725 | Time(s) 0.2383\nEpoch 00395 | Loss 1.9936 | Valid.Rand 0.1733 | Time(s) 0.2383\nEpoch 00396 | Loss 1.9774 | Valid.Rand 0.1737 | Time(s) 0.2383\nEpoch 00397 | Loss 1.8178 | Valid.Rand 0.1739 | Time(s) 0.2383\nEpoch 00398 | Loss 1.8110 | Valid.Rand 0.1726 | Time(s) 0.2384\nEpoch 00399 | Loss 1.7130 | Valid.Rand 0.1716 | Time(s) 0.2384\nEpoch 00400 | Loss 1.9808 | Valid.Rand 0.1700 | Time(s) 0.2383\nEpoch 00401 | Loss 2.0200 | Valid.Rand 0.1705 | Time(s) 0.2383\nEpoch 00402 | Loss 2.0334 | Valid.Rand 0.1676 | Time(s) 0.2383\nEpoch 00403 | Loss 1.7432 | Valid.Rand 0.1639 | Time(s) 0.2383\nEpoch 00404 | Loss 2.0256 | Valid.Rand 0.1619 | Time(s) 0.2384\nEpoch 00405 | Loss 1.7741 | Valid.Rand 0.1600 | Time(s) 0.2385\nEpoch 00406 | Loss 1.8607 | Valid.Rand 0.1578 | Time(s) 0.2383\nEpoch 00407 | Loss 2.0554 | Valid.Rand 0.1564 | Time(s) 0.2383\nEpoch 00408 | Loss 2.2784 | Valid.Rand 0.1536 | Time(s) 0.2382\nEpoch 00409 | Loss 2.1430 | Valid.Rand 0.1517 | Time(s) 0.2385\nEpoch 00410 | Loss 1.9977 | Valid.Rand 0.1469 | Time(s) 0.2387\nEpoch 00411 | Loss 1.9200 | Valid.Rand 0.1441 | Time(s) 0.2386\nEpoch 00412 | Loss 2.1603 | Valid.Rand 0.1433 | Time(s) 0.2385\nEpoch 00413 | Loss 1.8947 | Valid.Rand 0.1422 | Time(s) 0.2385\nEpoch 00414 | Loss 1.8441 | Valid.Rand 0.1476 | Time(s) 0.2383\nEpoch 00415 | Loss 1.6123 | Valid.Rand 0.1521 | Time(s) 0.2383\nEpoch 00416 | Loss 1.6222 | Valid.Rand 0.1576 | Time(s) 0.2383\nEpoch 00417 | Loss 2.1539 | Valid.Rand 0.1586 | Time(s) 0.2382\nEpoch 00418 | Loss 1.7496 | Valid.Rand 0.1619 | Time(s) 0.2383\nEpoch 00419 | Loss 2.0200 | Valid.Rand 0.1624 | Time(s) 0.2386\nEpoch 00420 | Loss 2.0728 | Valid.Rand 0.1622 | Time(s) 0.2385\nEpoch 00421 | Loss 1.9535 | Valid.Rand 0.1659 | Time(s) 0.2384\nEpoch 00422 | Loss 2.0060 | Valid.Rand 0.1709 | Time(s) 0.2384\nEpoch 00423 | Loss 1.6367 | Valid.Rand 0.1730 | Time(s) 0.2383\nEpoch 00424 | Loss 1.7819 | Valid.Rand 0.1735 | Time(s) 0.2382\nEpoch 00425 | Loss 1.8525 | Valid.Rand 0.1737 | Time(s) 0.2383\nEpoch 00426 | Loss 1.8997 | Valid.Rand 0.1765 | Time(s) 0.2383\nEpoch 00427 | Loss 2.0427 | Valid.Rand 0.1759 | Time(s) 0.2383\nEpoch 00428 | Loss 2.0296 | Valid.Rand 0.1761 | Time(s) 0.2382\nEpoch 00429 | Loss 1.6007 | Valid.Rand 0.1777 | Time(s) 0.2383\nEpoch 00430 | Loss 1.7363 | Valid.Rand 0.1800 | Time(s) 0.2382\nEpoch 00431 | Loss 1.7797 | Valid.Rand 0.1802 | Time(s) 0.2383\nEpoch 00432 | Loss 1.6659 | Valid.Rand 0.1780 | Time(s) 0.2384\nEpoch 00433 | Loss 1.9752 | Valid.Rand 0.1777 | Time(s) 0.2383\nEpoch 00434 | Loss 1.9532 | Valid.Rand 0.1764 | Time(s) 0.2383\nEpoch 00435 | Loss 2.2839 | Valid.Rand 0.1747 | Time(s) 0.2382\nEpoch 00436 | Loss 1.7611 | Valid.Rand 0.1710 | Time(s) 0.2382\nEpoch 00437 | Loss 1.9917 | Valid.Rand 0.1695 | Time(s) 0.2381\nEpoch 00438 | Loss 1.9657 | Valid.Rand 0.1632 | Time(s) 0.2381\nEpoch 00439 | Loss 1.7414 | Valid.Rand 0.1577 | Time(s) 0.2381\nEpoch 00440 | Loss 1.9080 | Valid.Rand 0.1512 | Time(s) 0.2382\nEpoch 00441 | Loss 2.2024 | Valid.Rand 0.1481 | Time(s) 0.2381\nEpoch 00442 | Loss 1.9794 | Valid.Rand 0.1470 | Time(s) 0.2381\nEpoch 00443 | Loss 1.7741 | Valid.Rand 0.1482 | Time(s) 0.2381\nEpoch 00444 | Loss 1.9093 | Valid.Rand 0.1466 | Time(s) 0.2381\nEpoch 00445 | Loss 2.2102 | Valid.Rand 0.1454 | Time(s) 0.2380\nEpoch 00446 | Loss 2.3675 | Valid.Rand 0.1398 | Time(s) 0.2379\nEpoch 00447 | Loss 2.0384 | Valid.Rand 0.1401 | Time(s) 0.2378\nEpoch 00448 | Loss 1.9965 | Valid.Rand 0.1416 | Time(s) 0.2379\nEpoch 00449 | Loss 1.8114 | Valid.Rand 0.1436 | Time(s) 0.2379\nEpoch 00450 | Loss 2.1971 | Valid.Rand 0.1440 | Time(s) 0.2380\nEpoch 00451 | Loss 2.1852 | Valid.Rand 0.1443 | Time(s) 0.2380\nEpoch 00452 | Loss 1.9299 | Valid.Rand 0.1438 | Time(s) 0.2380\nEpoch 00453 | Loss 1.8174 | Valid.Rand 0.1420 | Time(s) 0.2379\nEpoch 00454 | Loss 1.8380 | Valid.Rand 0.1403 | Time(s) 0.2379\nEpoch 00455 | Loss 1.9308 | Valid.Rand 0.1413 | Time(s) 0.2379\nEpoch 00456 | Loss 1.7510 | Valid.Rand 0.1416 | Time(s) 0.2378\nEpoch 00457 | Loss 2.1278 | Valid.Rand 0.1443 | Time(s) 0.2378\nEpoch 00458 | Loss 1.9245 | Valid.Rand 0.1453 | Time(s) 0.2378\nEpoch 00459 | Loss 1.8718 | Valid.Rand 0.1506 | Time(s) 0.2377\nEpoch 00460 | Loss 1.8779 | Valid.Rand 0.1524 | Time(s) 0.2378\nEpoch 00461 | Loss 1.6761 | Valid.Rand 0.1508 | Time(s) 0.2377\nEpoch 00462 | Loss 1.8434 | Valid.Rand 0.1514 | Time(s) 0.2377\nEpoch 00463 | Loss 1.8027 | Valid.Rand 0.1519 | Time(s) 0.2377\nEpoch 00464 | Loss 1.7080 | Valid.Rand 0.1522 | Time(s) 0.2377\nEpoch 00465 | Loss 1.9176 | Valid.Rand 0.1515 | Time(s) 0.2376\nEpoch 00466 | Loss 1.8223 | Valid.Rand 0.1518 | Time(s) 0.2376\nEpoch 00467 | Loss 1.8840 | Valid.Rand 0.1532 | Time(s) 0.2377\nEpoch 00468 | Loss 2.1175 | Valid.Rand 0.1494 | Time(s) 0.2376\nEpoch 00469 | Loss 1.6831 | Valid.Rand 0.1483 | Time(s) 0.2377\nEpoch 00470 | Loss 2.3627 | Valid.Rand 0.1451 | Time(s) 0.2376\nEpoch 00471 | Loss 1.7642 | Valid.Rand 0.1430 | Time(s) 0.2376\nEpoch 00472 | Loss 1.6733 | Valid.Rand 0.1425 | Time(s) 0.2375\nEpoch 00473 | Loss 1.9873 | Valid.Rand 0.1402 | Time(s) 0.2375\nEpoch 00474 | Loss 1.7028 | Valid.Rand 0.1382 | Time(s) 0.2375\nEpoch 00475 | Loss 1.6735 | Valid.Rand 0.1373 | Time(s) 0.2376\nEpoch 00476 | Loss 1.8447 | Valid.Rand 0.1449 | Time(s) 0.2375\nEpoch 00477 | Loss 2.3481 | Valid.Rand 0.1497 | Time(s) 0.2375\nEpoch 00478 | Loss 1.8531 | Valid.Rand 0.1490 | Time(s) 0.2375\nEpoch 00479 | Loss 1.8990 | Valid.Rand 0.1469 | Time(s) 0.2375\nEpoch 00480 | Loss 2.0567 | Valid.Rand 0.1436 | Time(s) 0.2376\nEpoch 00481 | Loss 1.6215 | Valid.Rand 0.1423 | Time(s) 0.2375\nEpoch 00482 | Loss 1.5665 | Valid.Rand 0.1412 | Time(s) 0.2375\nEpoch 00483 | Loss 1.8870 | Valid.Rand 0.1367 | Time(s) 0.2375\nEpoch 00484 | Loss 1.6149 | Valid.Rand 0.1378 | Time(s) 0.2375\nEpoch 00485 | Loss 2.2475 | Valid.Rand 0.1350 | Time(s) 0.2374\nEpoch 00486 | Loss 2.3694 | Valid.Rand 0.1365 | Time(s) 0.2373\nEpoch 00487 | Loss 2.3539 | Valid.Rand 0.1414 | Time(s) 0.2374\nEpoch 00488 | Loss 2.5476 | Valid.Rand 0.1457 | Time(s) 0.2374\nEpoch 00489 | Loss 1.9260 | Valid.Rand 0.1511 | Time(s) 0.2374\nEpoch 00490 | Loss 2.1808 | Valid.Rand 0.1547 | Time(s) 0.2373\n"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "net = Net(features.shape[1], 21, len(np.unique(labels)))\n",
    "#print(net)\n",
    "\n",
    "optimizer = th.optim.Adam(net.parameters(), lr=1e-3)\n",
    "net.train() # Set to training mode (use dropout)\n",
    "\n",
    "dur = []\n",
    "for epoch in range(500):\n",
    "    if epoch >=3:\n",
    "        t0 = time.time()\n",
    "\n",
    "    # Compute loss for test nodes (only for validation, not used by optimizer)\n",
    "    net.eval()\n",
    "    prediction = net(g, features)\n",
    "    train_rand=pf.rand_score(labels[mask].numpy(),np.argmax(prediction[mask].detach().numpy(), axis=1)\n",
    "    validation_rand=pf.rand_score(labels[1-mask].numpy(),np.argmax(prediction[1-mask].detach().numpy(), axis=1))\n",
    "    net.train()\n",
    "\n",
    "    # Compute loss for train nodes\n",
    "    logits = net(g, features)\n",
    "\n",
    "    loss = loss_function.approximate_loss(logits,mask,nclasses=5)\n",
    "\n",
    "    #loss = F.nll_loss(logits[mask], labels[mask])\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch >=3:\n",
    "        dur.append(time.time() - t0)\n",
    "\n",
    "    print(\"Epoch {:05d} | Loss {:.4f} | Valid.Rand {:.4f} | Time(s) {:.4f}\".format(\n",
    "            epoch, loss.item(), validation, np.mean(dur)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 6],\n       [0, 3],\n       [2, 2],\n       [2, 2],\n       [0, 6],\n       [6, 4],\n       [4, 0],\n       [4, 0],\n       [0, 2],\n       [0, 4]], dtype=int64)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualise predictions\n",
    "net.eval() # Set net to evaluation mode (deactivates dropout)\n",
    "final_prediction = net(g, features).detach()\n",
    "a = np.transpose(np.vstack([final_prediction[mask].numpy().argmax(axis=1),labels[mask].numpy()]))\n",
    "a[a[:,0].argsort()][np.random.choice(range(a.shape[0]),size=10)]\n",
    "# as can be seen, the net predicts other labels, but gets the clusters right :)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>All</th>\n      <th>Train</th>\n      <th>Test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Mutual Information</th>\n      <td>0.200959</td>\n      <td>0.668763</td>\n      <td>0.193395</td>\n    </tr>\n    <tr>\n      <th>Rand-Index</th>\n      <td>0.092219</td>\n      <td>0.456485</td>\n      <td>0.088449</td>\n    </tr>\n    <tr>\n      <th>Variation of Information</th>\n      <td>2.655766</td>\n      <td>0.936472</td>\n      <td>2.667611</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                              All      Train      Test\nMutual Information        0.200959  0.668763  0.193395\nRand-Index                0.092219  0.456485  0.088449\nVariation of Information  2.655766  0.936472  2.667611"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval() # Set net to evaluation mode (deactivates dropout)\n",
    "final_prediction = net(g, features).detach()\n",
    "pf.performance_as_df(labels,final_prediction,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}