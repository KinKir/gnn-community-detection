{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "LGNN Semi-supervised.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "aC7suSihFigY",
        "PoEuu1sgmr9s"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrian-lison/gnn-community-detection/blob/master/Notebooks/LGNN_Semi_supervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vij82xvSwQdb"
      },
      "source": [
        "# Model #4 LGNN\n",
        "----------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install dgl"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dgl\n",
        "import dgl\n",
        "import dgl.function as fn\n",
        "from dgl import DGLGraph\n",
        "from dgl.data import citation_graph as citegrh\n",
        "\n",
        "# pytorch\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# other\n",
        "import time\n",
        "import numpy as np\n",
        "import random as rng\n",
        "import scipy.sparse as ss\n",
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## GNN Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Return a list containing features gathered from multiple radius.\n",
        "import dgl.function as fn\n",
        "def aggregate_radius(radius, g, z):\n",
        "    # initializing list to collect message passing result\n",
        "    z_list = []\n",
        "    g.ndata['z'] = z\n",
        "    # pulling message from 1-hop neighbourhood\n",
        "    g.update_all(fn.copy_src(src='z', out='m'), fn.sum(msg='m', out='z'))\n",
        "    z_list.append(g.ndata['z'])\n",
        "    for i in range(radius - 1):\n",
        "        for j in range(2 ** i):\n",
        "            #pulling message from 2^j neighborhood\n",
        "            g.update_all(fn.copy_src(src='z', out='m'), fn.sum(msg='m', out='z'))\n",
        "        z_list.append(g.ndata['z'])\n",
        "    return z_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LGNNCore(nn.Module):\n",
        "    def __init__(self, in_feats, out_feats, radius):\n",
        "        super(LGNNCore, self).__init__()\n",
        "        self.out_feats = out_feats\n",
        "        self.radius = radius\n",
        "\n",
        "        self.linear_prev = nn.Linear(in_feats, out_feats)\n",
        "        self.linear_deg = nn.Linear(in_feats, out_feats)\n",
        "        self.linear_radius = nn.ModuleList(\n",
        "                [nn.Linear(in_feats, out_feats) for i in range(radius)])\n",
        "        self.linear_fuse = nn.Linear(in_feats, out_feats)\n",
        "        self.bn = nn.BatchNorm1d(out_feats)\n",
        "\n",
        "    def forward(self, g, feat_a, feat_b, deg, pm_pd):\n",
        "        # term \"prev\"\n",
        "        prev_proj = self.linear_prev(feat_a)\n",
        "        # term \"deg\"\n",
        "        deg_proj = self.linear_deg(deg * feat_a)\n",
        "\n",
        "        # term \"radius\"\n",
        "        # aggregate 2^j-hop features\n",
        "        hop2j_list = aggregate_radius(self.radius, g, feat_a)\n",
        "        # apply linear transformation\n",
        "        hop2j_list = [linear(x) for linear, x in zip(self.linear_radius, hop2j_list)]\n",
        "        radius_proj = sum(hop2j_list)\n",
        "\n",
        "        # term \"fuse\"\n",
        "        fuse = self.linear_fuse(th.mm(pm_pd, feat_b))\n",
        "\n",
        "        # sum them together\n",
        "        result = prev_proj + deg_proj + radius_proj + fuse\n",
        "\n",
        "        # skip connection and batch norm\n",
        "        n = self.out_feats // 2\n",
        "        result = th.cat([result[:, :n], F.relu(result[:, n:])], 1)\n",
        "        result = self.bn(result)\n",
        "\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LGNNLayer(nn.Module):\n",
        "    def __init__(self, in_feats, out_feats, radius):\n",
        "        super(LGNNLayer, self).__init__()\n",
        "        self.g_layer = LGNNCore(in_feats, out_feats, radius)\n",
        "        self.lg_layer = LGNNCore(in_feats, out_feats, radius)\n",
        "\n",
        "    def forward(self, g, lg, x, lg_x, deg_g, deg_lg, pm_pd):\n",
        "        next_x = self.g_layer(g, x, lg_x, deg_g, pm_pd)\n",
        "        pm_pd_y = th.transpose(pm_pd, 0, 1)\n",
        "        next_lg_x = self.lg_layer(lg, lg_x, x, deg_lg, pm_pd_y)\n",
        "        return next_x, next_lg_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LGNN(nn.Module):\n",
        "    def __init__(self, radius):\n",
        "        super(LGNN, self).__init__()\n",
        "        self.layer1 = LGNNLayer(1, 16, radius)  # input is scalar feature\n",
        "        self.layer2 = LGNNLayer(16, 16, radius)  # hidden size is 16\n",
        "        self.layer3 = LGNNLayer(16, 16, radius)\n",
        "        self.linear = nn.Linear(16, 7)  # predice seven classes\n",
        "\n",
        "    def forward(self, g, lg, pm_pd):\n",
        "        # compute the degrees\n",
        "        deg_g = g.in_degrees().float().unsqueeze(1)\n",
        "        deg_lg = lg.in_degrees().float().unsqueeze(1)\n",
        "        # use degree as the input feature\n",
        "        x, lg_x = deg_g, deg_lg\n",
        "        x, lg_x = self.layer1(g, lg, x, lg_x, deg_g, deg_lg, pm_pd)\n",
        "        x, lg_x = self.layer2(g, lg, x, lg_x, deg_g, deg_lg, pm_pd)\n",
        "        x, lg_x = self.layer3(g, lg, x, lg_x, deg_g, deg_lg, pm_pd)\n",
        "        return self.linear(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "We have 2708 nodes. We have 10556 edges. Before DGL Graph adding edges: 10556\n"
        }
      ],
      "source": [
        "#Loading CORA\n",
        "data = citegrh.load_cora()\n",
        "features = th.FloatTensor(data.features)\n",
        "labels = th.LongTensor(data.labels)\n",
        "mask = th.ByteTensor(data.train_mask)\n",
        "g = data.graph\n",
        "g2 = data.graph\n",
        "# removing doesnt work\n",
        "#g.remove_edges_from(g.selfloop_edges())\n",
        "g = DGLGraph(g)\n",
        "#g.add_edges(g.nodes(), g.nodes()) #What does this do?\n",
        "print('We have %d nodes. We have %d edges. Before DGL Graph adding edges: %d' % (g.number_of_nodes(),g.number_of_edges(),g2.number_of_edges()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "2708"
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "edges_per_node = {}\n",
        "for x in g2.adj.items():\n",
        "  z = [] \n",
        "  for i in x[1]:\n",
        "    z.append(i)\n",
        "  edges_per_node[x[0]] = z\n",
        "edges_per_node[0]\n",
        "len(edges_per_node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "[410, 471, 552, 565]"
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "edges_per_node[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "colab_type": "code",
        "id": "PrMUl8sDyyJV",
        "outputId": "ce7d4b6b-dc6d-4867-e187-f49f1fe92481"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<2708x10556 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 10556 stored elements in COOrdinate format>"
            ]
          },
          "execution_count": 14,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from scipy.sparse import lil_matrix\n",
        "matrix_p2 = lil_matrix((g2.number_of_nodes(),g2.number_of_edges()))\n",
        "for i in range(len(edges_per_node)):\n",
        "  matrix_p2[i,edges_per_node[i]] = 1\n",
        "new_pdw = ss.coo_matrix(matrix_p2,dtype=\"int64\")\n",
        "new_pdw"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Select Training Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "K-YAeCUSn0qn"
      },
      "outputs": [],
      "source": [
        "#inputs_pmpd = nx.to_scipy_sparse_matrix(g2,dtype=\"int64\",  format='coo')\n",
        "inputs_pmpd = new_pdw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "percentage_train = 0.02\n",
        "\n",
        "with open(\"data/cora_permutation1.pickle\",\"rb\") as f:\n",
        "    perm1 = pickle.load(f)\n",
        "mask = np.zeros(g.number_of_nodes())\n",
        "mask[perm1[range(int(percentage_train*g.number_of_nodes()))]] = 1\n",
        "mask = th.ByteTensor(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "lL3JDs8GmG7t",
        "outputId": "a09065cb-8a5e-44e4-f6cb-c8bc52792ebb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 | Loss: 1.9892 | Total: 2.0069 | Accuracy: 0.1540 | Accuracy excluding open nodes: 0.0603 | Open nodes: 0\n",
            "Epoch 1 | Loss: 1.9219 | Total: 1.9453 | Accuracy: 0.1592 | Accuracy excluding open nodes: 0.0660 | Open nodes: 0\n",
            "Epoch 2 | Loss: 1.8484 | Total: 1.8737 | Accuracy: 0.2585 | Accuracy excluding open nodes: 0.1764 | Open nodes: 0\n",
            "Epoch 3 | Loss: 1.7489 | Total: 1.7725 | Accuracy: 0.3283 | Accuracy excluding open nodes: 0.2539 | Open nodes: 0\n",
            "Epoch 4 | Loss: 1.7265 | Total: 1.7530 | Accuracy: 0.3039 | Accuracy excluding open nodes: 0.2268 | Open nodes: 0\n",
            "Epoch 5 | Loss: 1.6909 | Total: 1.7279 | Accuracy: 0.3353 | Accuracy excluding open nodes: 0.2617 | Open nodes: 0\n",
            "Epoch 6 | Loss: 1.6665 | Total: 1.7025 | Accuracy: 0.3486 | Accuracy excluding open nodes: 0.2765 | Open nodes: 0\n",
            "Epoch 7 | Loss: 1.6450 | Total: 1.6849 | Accuracy: 0.3744 | Accuracy excluding open nodes: 0.3052 | Open nodes: 0\n",
            "Epoch 8 | Loss: 1.6231 | Total: 1.6656 | Accuracy: 0.4066 | Accuracy excluding open nodes: 0.3409 | Open nodes: 0\n",
            "Epoch 9 | Loss: 1.5989 | Total: 1.6457 | Accuracy: 0.4849 | Accuracy excluding open nodes: 0.4278 | Open nodes: 0\n",
            "Epoch 10 | Loss: 1.5907 | Total: 1.6354 | Accuracy: 0.4738 | Accuracy excluding open nodes: 0.4155 | Open nodes: 0\n",
            "Epoch 11 | Loss: 1.5729 | Total: 1.6233 | Accuracy: 0.4631 | Accuracy excluding open nodes: 0.4036 | Open nodes: 0\n",
            "Epoch 12 | Loss: 1.5643 | Total: 1.6214 | Accuracy: 0.4679 | Accuracy excluding open nodes: 0.4089 | Open nodes: 0\n",
            "Epoch 13 | Loss: 1.5512 | Total: 1.6136 | Accuracy: 0.4664 | Accuracy excluding open nodes: 0.4073 | Open nodes: 0\n",
            "Epoch 14 | Loss: 1.5380 | Total: 1.6050 | Accuracy: 0.4701 | Accuracy excluding open nodes: 0.4114 | Open nodes: 0\n",
            "Epoch 15 | Loss: 1.5192 | Total: 1.5926 | Accuracy: 0.4694 | Accuracy excluding open nodes: 0.4106 | Open nodes: 0\n",
            "Epoch 16 | Loss: 1.5008 | Total: 1.5863 | Accuracy: 0.4716 | Accuracy excluding open nodes: 0.4130 | Open nodes: 0\n",
            "Epoch 17 | Loss: 1.4942 | Total: 1.5810 | Accuracy: 0.4671 | Accuracy excluding open nodes: 0.4081 | Open nodes: 0\n",
            "Epoch 18 | Loss: 1.4833 | Total: 1.5737 | Accuracy: 0.4697 | Accuracy excluding open nodes: 0.4110 | Open nodes: 0\n",
            "Epoch 19 | Loss: 1.4712 | Total: 1.5674 | Accuracy: 0.4682 | Accuracy excluding open nodes: 0.4094 | Open nodes: 0\n",
            "Epoch 20 | Loss: 1.4636 | Total: 1.5643 | Accuracy: 0.4627 | Accuracy excluding open nodes: 0.4032 | Open nodes: 0\n",
            "Epoch 21 | Loss: 1.4504 | Total: 1.5560 | Accuracy: 0.4686 | Accuracy excluding open nodes: 0.4098 | Open nodes: 0\n",
            "Epoch 22 | Loss: 1.4452 | Total: 1.5640 | Accuracy: 0.4738 | Accuracy excluding open nodes: 0.4155 | Open nodes: 0\n",
            "Epoch 23 | Loss: 1.4380 | Total: 1.5424 | Accuracy: 0.4694 | Accuracy excluding open nodes: 0.4106 | Open nodes: 0\n",
            "Epoch 24 | Loss: 1.4252 | Total: 1.5466 | Accuracy: 0.4730 | Accuracy excluding open nodes: 0.4147 | Open nodes: 0\n",
            "Epoch 25 | Loss: 1.4153 | Total: 1.5461 | Accuracy: 0.4671 | Accuracy excluding open nodes: 0.4081 | Open nodes: 0\n",
            "Epoch 26 | Loss: 1.3998 | Total: 1.5415 | Accuracy: 0.4675 | Accuracy excluding open nodes: 0.4085 | Open nodes: 0\n",
            "Epoch 27 | Loss: 1.3848 | Total: 1.5384 | Accuracy: 0.4712 | Accuracy excluding open nodes: 0.4126 | Open nodes: 0\n",
            "Epoch 28 | Loss: 1.3851 | Total: 1.5299 | Accuracy: 0.4675 | Accuracy excluding open nodes: 0.4085 | Open nodes: 0\n",
            "Epoch 29 | Loss: 1.3823 | Total: 1.5195 | Accuracy: 0.4649 | Accuracy excluding open nodes: 0.4057 | Open nodes: 0\n",
            "Epoch 30 | Loss: 1.3731 | Total: 1.5011 | Accuracy: 0.4742 | Accuracy excluding open nodes: 0.4159 | Open nodes: 0\n",
            "Epoch 31 | Loss: 1.3610 | Total: 1.4866 | Accuracy: 0.4771 | Accuracy excluding open nodes: 0.4192 | Open nodes: 0\n",
            "Epoch 32 | Loss: 1.3488 | Total: 1.4881 | Accuracy: 0.4826 | Accuracy excluding open nodes: 0.4253 | Open nodes: 0\n",
            "Epoch 33 | Loss: 1.4237 | Total: 1.5548 | Accuracy: 0.4280 | Accuracy excluding open nodes: 0.3646 | Open nodes: 0\n",
            "Epoch 34 | Loss: 1.3313 | Total: 1.5288 | Accuracy: 0.4679 | Accuracy excluding open nodes: 0.4089 | Open nodes: 0\n",
            "Epoch 35 | Loss: 1.3403 | Total: 1.5345 | Accuracy: 0.4657 | Accuracy excluding open nodes: 0.4065 | Open nodes: 0\n",
            "Epoch 36 | Loss: 1.3322 | Total: 1.5355 | Accuracy: 0.4686 | Accuracy excluding open nodes: 0.4098 | Open nodes: 0\n",
            "Epoch 37 | Loss: 1.3192 | Total: 1.5068 | Accuracy: 0.4808 | Accuracy excluding open nodes: 0.4233 | Open nodes: 0\n",
            "Epoch 38 | Loss: 1.3121 | Total: 1.5367 | Accuracy: 0.4841 | Accuracy excluding open nodes: 0.4270 | Open nodes: 0\n",
            "Epoch 39 | Loss: 1.3044 | Total: 1.5341 | Accuracy: 0.4849 | Accuracy excluding open nodes: 0.4278 | Open nodes: 0\n",
            "Epoch 40 | Loss: 1.3165 | Total: 1.4845 | Accuracy: 0.4915 | Accuracy excluding open nodes: 0.4352 | Open nodes: 0\n",
            "Epoch 41 | Loss: 1.3250 | Total: 1.5604 | Accuracy: 0.4642 | Accuracy excluding open nodes: 0.4048 | Open nodes: 0\n",
            "Epoch 42 | Loss: 1.2835 | Total: 1.5297 | Accuracy: 0.4771 | Accuracy excluding open nodes: 0.4192 | Open nodes: 0\n",
            "Epoch 43 | Loss: 1.3297 | Total: 1.4744 | Accuracy: 0.4819 | Accuracy excluding open nodes: 0.4245 | Open nodes: 0\n",
            "Epoch 44 | Loss: 1.2931 | Total: 1.4473 | Accuracy: 0.5089 | Accuracy excluding open nodes: 0.4545 | Open nodes: 0\n",
            "Epoch 45 | Loss: 1.2845 | Total: 1.4419 | Accuracy: 0.5089 | Accuracy excluding open nodes: 0.4545 | Open nodes: 0\n",
            "Epoch 46 | Loss: 1.2783 | Total: 1.4606 | Accuracy: 0.5177 | Accuracy excluding open nodes: 0.4643 | Open nodes: 0\n",
            "Epoch 47 | Loss: 1.2621 | Total: 1.5137 | Accuracy: 0.5103 | Accuracy excluding open nodes: 0.4561 | Open nodes: 0\n",
            "Epoch 48 | Loss: 1.2613 | Total: 1.5216 | Accuracy: 0.4882 | Accuracy excluding open nodes: 0.4315 | Open nodes: 0\n",
            "Epoch 49 | Loss: 1.2522 | Total: 1.5180 | Accuracy: 0.5007 | Accuracy excluding open nodes: 0.4454 | Open nodes: 0\n",
            "Epoch 50 | Loss: 1.2592 | Total: 1.5214 | Accuracy: 0.5044 | Accuracy excluding open nodes: 0.4495 | Open nodes: 0\n",
            "Epoch 51 | Loss: 1.2429 | Total: 1.5198 | Accuracy: 0.5100 | Accuracy excluding open nodes: 0.4557 | Open nodes: 0\n",
            "Epoch 52 | Loss: 1.2733 | Total: 1.5413 | Accuracy: 0.4908 | Accuracy excluding open nodes: 0.4344 | Open nodes: 0\n",
            "Epoch 53 | Loss: 1.2390 | Total: 1.5119 | Accuracy: 0.5292 | Accuracy excluding open nodes: 0.4770 | Open nodes: 0\n",
            "Epoch 54 | Loss: 1.2385 | Total: 1.4800 | Accuracy: 0.5295 | Accuracy excluding open nodes: 0.4774 | Open nodes: 0\n",
            "Epoch 55 | Loss: 1.2305 | Total: 1.5245 | Accuracy: 0.5270 | Accuracy excluding open nodes: 0.4746 | Open nodes: 0\n",
            "Epoch 56 | Loss: 1.2155 | Total: 1.5194 | Accuracy: 0.5273 | Accuracy excluding open nodes: 0.4750 | Open nodes: 0\n",
            "Epoch 57 | Loss: 1.2023 | Total: 1.5058 | Accuracy: 0.5425 | Accuracy excluding open nodes: 0.4918 | Open nodes: 0\n",
            "Epoch 58 | Loss: 1.1918 | Total: 1.5346 | Accuracy: 0.5377 | Accuracy excluding open nodes: 0.4865 | Open nodes: 0\n",
            "Epoch 59 | Loss: 1.2080 | Total: 1.5551 | Accuracy: 0.5284 | Accuracy excluding open nodes: 0.4762 | Open nodes: 0\n",
            "Epoch 60 | Loss: 1.1777 | Total: 1.5247 | Accuracy: 0.5314 | Accuracy excluding open nodes: 0.4795 | Open nodes: 0\n",
            "Epoch 61 | Loss: 1.1626 | Total: 1.4999 | Accuracy: 0.5318 | Accuracy excluding open nodes: 0.4799 | Open nodes: 0\n",
            "Epoch 62 | Loss: 1.1636 | Total: 1.5005 | Accuracy: 0.5343 | Accuracy excluding open nodes: 0.4828 | Open nodes: 0\n",
            "Epoch 63 | Loss: 1.1594 | Total: 1.4984 | Accuracy: 0.5292 | Accuracy excluding open nodes: 0.4770 | Open nodes: 0\n",
            "Epoch 64 | Loss: 1.1551 | Total: 1.5166 | Accuracy: 0.5351 | Accuracy excluding open nodes: 0.4836 | Open nodes: 0\n",
            "Epoch 65 | Loss: 1.1491 | Total: 1.5412 | Accuracy: 0.5347 | Accuracy excluding open nodes: 0.4832 | Open nodes: 0\n",
            "Epoch 66 | Loss: 1.1429 | Total: 1.5513 | Accuracy: 0.5240 | Accuracy excluding open nodes: 0.4713 | Open nodes: 0\n",
            "Epoch 67 | Loss: 1.1410 | Total: 1.5526 | Accuracy: 0.5177 | Accuracy excluding open nodes: 0.4643 | Open nodes: 0\n",
            "Epoch 68 | Loss: 1.1374 | Total: 1.5530 | Accuracy: 0.5174 | Accuracy excluding open nodes: 0.4639 | Open nodes: 0\n",
            "Epoch 69 | Loss: 1.1335 | Total: 1.5522 | Accuracy: 0.5166 | Accuracy excluding open nodes: 0.4631 | Open nodes: 0\n",
            "Epoch 70 | Loss: 1.1229 | Total: 1.5489 | Accuracy: 0.5144 | Accuracy excluding open nodes: 0.4606 | Open nodes: 0\n",
            "Epoch 71 | Loss: 1.1156 | Total: 1.5516 | Accuracy: 0.5262 | Accuracy excluding open nodes: 0.4737 | Open nodes: 0\n",
            "Epoch 72 | Loss: 1.1144 | Total: 1.5598 | Accuracy: 0.5236 | Accuracy excluding open nodes: 0.4709 | Open nodes: 0\n",
            "Epoch 73 | Loss: 1.1083 | Total: 1.5696 | Accuracy: 0.5222 | Accuracy excluding open nodes: 0.4692 | Open nodes: 0\n",
            "Epoch 74 | Loss: 1.1006 | Total: 1.5798 | Accuracy: 0.5214 | Accuracy excluding open nodes: 0.4684 | Open nodes: 0\n",
            "Epoch 75 | Loss: 1.0915 | Total: 1.5728 | Accuracy: 0.5192 | Accuracy excluding open nodes: 0.4660 | Open nodes: 0\n",
            "Epoch 76 | Loss: 1.0916 | Total: 1.5718 | Accuracy: 0.5207 | Accuracy excluding open nodes: 0.4676 | Open nodes: 0\n",
            "Epoch 77 | Loss: 1.0949 | Total: 1.5850 | Accuracy: 0.5185 | Accuracy excluding open nodes: 0.4651 | Open nodes: 0\n",
            "Epoch 78 | Loss: 1.0895 | Total: 1.5417 | Accuracy: 0.5166 | Accuracy excluding open nodes: 0.4631 | Open nodes: 0\n",
            "Epoch 79 | Loss: 1.1065 | Total: 1.5462 | Accuracy: 0.5066 | Accuracy excluding open nodes: 0.4520 | Open nodes: 0\n",
            "Epoch 80 | Loss: 1.0943 | Total: 1.5474 | Accuracy: 0.5044 | Accuracy excluding open nodes: 0.4495 | Open nodes: 0\n",
            "Epoch 81 | Loss: 1.1099 | Total: 1.5525 | Accuracy: 0.5044 | Accuracy excluding open nodes: 0.4495 | Open nodes: 0\n",
            "Epoch 82 | Loss: 1.1040 | Total: 1.5639 | Accuracy: 0.5063 | Accuracy excluding open nodes: 0.4516 | Open nodes: 0\n",
            "Epoch 83 | Loss: 1.0838 | Total: 1.5683 | Accuracy: 0.5111 | Accuracy excluding open nodes: 0.4569 | Open nodes: 0\n",
            "Epoch 84 | Loss: 1.0863 | Total: 1.6078 | Accuracy: 0.5048 | Accuracy excluding open nodes: 0.4500 | Open nodes: 0\n",
            "Epoch 85 | Loss: 1.0780 | Total: 1.5875 | Accuracy: 0.5081 | Accuracy excluding open nodes: 0.4537 | Open nodes: 0\n",
            "Epoch 86 | Loss: 1.0834 | Total: 1.5911 | Accuracy: 0.5107 | Accuracy excluding open nodes: 0.4565 | Open nodes: 0\n",
            "Epoch 87 | Loss: 1.0730 | Total: 1.5824 | Accuracy: 0.5133 | Accuracy excluding open nodes: 0.4594 | Open nodes: 0\n",
            "Epoch 88 | Loss: 1.0666 | Total: 1.5682 | Accuracy: 0.5284 | Accuracy excluding open nodes: 0.4762 | Open nodes: 0\n",
            "Epoch 89 | Loss: 1.0684 | Total: 1.5678 | Accuracy: 0.5236 | Accuracy excluding open nodes: 0.4709 | Open nodes: 0\n",
            "Epoch 90 | Loss: 1.0518 | Total: 1.5707 | Accuracy: 0.5266 | Accuracy excluding open nodes: 0.4742 | Open nodes: 0\n",
            "Epoch 91 | Loss: 1.0444 | Total: 1.5980 | Accuracy: 0.5266 | Accuracy excluding open nodes: 0.4742 | Open nodes: 0\n",
            "Epoch 92 | Loss: 1.0445 | Total: 1.6376 | Accuracy: 0.5207 | Accuracy excluding open nodes: 0.4676 | Open nodes: 0\n",
            "Epoch 93 | Loss: 1.0519 | Total: 1.6096 | Accuracy: 0.5122 | Accuracy excluding open nodes: 0.4582 | Open nodes: 0\n",
            "Epoch 94 | Loss: 1.0623 | Total: 1.5490 | Accuracy: 0.5388 | Accuracy excluding open nodes: 0.4877 | Open nodes: 0\n",
            "Epoch 95 | Loss: 1.0703 | Total: 1.5324 | Accuracy: 0.5358 | Accuracy excluding open nodes: 0.4844 | Open nodes: 0\n",
            "Epoch 96 | Loss: 1.0645 | Total: 1.5281 | Accuracy: 0.5277 | Accuracy excluding open nodes: 0.4754 | Open nodes: 0\n",
            "Epoch 97 | Loss: 1.0445 | Total: 1.5327 | Accuracy: 0.5188 | Accuracy excluding open nodes: 0.4655 | Open nodes: 0\n",
            "Epoch 98 | Loss: 1.0791 | Total: 1.5831 | Accuracy: 0.4993 | Accuracy excluding open nodes: 0.4438 | Open nodes: 0\n",
            "Epoch 99 | Loss: 1.0401 | Total: 1.5558 | Accuracy: 0.5255 | Accuracy excluding open nodes: 0.4729 | Open nodes: 0\n"
          ]
        }
      ],
      "source": [
        "# create the model\n",
        "net = LGNN(radius=3)\n",
        "# define the optimizer\n",
        "optimizer = th.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# a util function to convert a scipy.coo_matrix to torch.SparseFloat\n",
        "def sparse2th(mat):\n",
        "    value = mat.data\n",
        "    indices = th.LongTensor([mat.row, mat.col])\n",
        "    tensor = th.sparse.FloatTensor(indices, th.from_numpy(value).float(), mat.shape)\n",
        "    return tensor\n",
        "\n",
        "all_logits = []\n",
        "\n",
        "pmpd = sparse2th(inputs_pmpd)\n",
        "lg = g.line_graph(backtracking=False)\n",
        "\n",
        "# train\n",
        "for epoch in range(100):\n",
        "\n",
        "    # Compute loss for test nodes (only for validation, not used by optimizer)\n",
        "    net.eval()\n",
        "    prediction = F.log_softmax(net(g, lg, pmpd),1)\n",
        "    val_loss = F.nll_loss(prediction.detach()[1-mask], labels[1-mask])\n",
        "    net.train()\n",
        "\n",
        "    logits = net(g, lg, pmpd)\n",
        "    # Save logits for visualization later\n",
        "    all_logits.append(logits.detach())\n",
        "    logp = F.log_softmax(logits, 1)\n",
        "\n",
        "    # Compute loss for train nodes\n",
        "    loss = F.nll_loss(logp[mask], labels[mask])\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    print('Epoch %d | Loss: %.4f | Total: %.4f' % (epoch, loss.item(), val_loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score as acc\n",
        "net.eval() # Set net to evaluation mode (deactivates dropout)\n",
        "final_prediction = F.log_softmax(net(g, lg, pmpd),1).detach()\n",
        "\n",
        "pred_sets = {\"All \":final_prediction,\"Train\":final_prediction[mask],\"Test\":final_prediction[1-mask]}\n",
        "label_sets = {\"All \":labels,\"Train\":labels[mask],\"Test\":labels[1-mask]}\n",
        "eval_functions = {\"NLL-Loss\":lambda y,x: F.nll_loss(x,y),\"Accuracy\":lambda y,x: acc(y,x.numpy().argmax(axis=1))}\n",
        "\n",
        "for name,func in eval_functions.items():\n",
        "    eval_message = f\"\\n{name}:\\n\"\n",
        "    for subset in pred_sets.keys():\n",
        "        eval_message += f\" {subset}: {func(label_sets[subset],pred_sets[subset]):.4f} |\"\n",
        "    print(eval_message)"
      ]
    }
  ]
}