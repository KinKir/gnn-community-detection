{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "LGNN Semi-supervised.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "aC7suSihFigY",
        "PoEuu1sgmr9s"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrian-lison/gnn-community-detection/blob/master/Notebooks/LGNN_Semi_supervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vij82xvSwQdb"
      },
      "source": [
        "# Model #4 LGNN\n",
        "----------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install dgl"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dgl\n",
        "import dgl\n",
        "import dgl.function as fn\n",
        "from dgl import DGLGraph\n",
        "from dgl.data import citation_graph as citegrh\n",
        "\n",
        "# pytorch\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# other\n",
        "import time\n",
        "import numpy as np\n",
        "import random as rng\n",
        "import scipy.sparse as ss\n",
        "import networkx as nx\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## GNN Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Return a list containing features gathered from multiple radius.\n",
        "import dgl.function as fn\n",
        "def aggregate_radius(radius, g, z):\n",
        "    # initializing list to collect message passing result\n",
        "    z_list = []\n",
        "    g.ndata['z'] = z\n",
        "    # pulling message from 1-hop neighbourhood\n",
        "    g.update_all(fn.copy_src(src='z', out='m'), fn.sum(msg='m', out='z'))\n",
        "    z_list.append(g.ndata['z'])\n",
        "    for i in range(radius - 1):\n",
        "        for j in range(2 ** i):\n",
        "            #pulling message from 2^j neighborhood\n",
        "            g.update_all(fn.copy_src(src='z', out='m'), fn.sum(msg='m', out='z'))\n",
        "        z_list.append(g.ndata['z'])\n",
        "    return z_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LGNNCore(nn.Module):\n",
        "    def __init__(self, in_feats, out_feats, radius):\n",
        "        super(LGNNCore, self).__init__()\n",
        "        self.out_feats = out_feats\n",
        "        self.radius = radius\n",
        "\n",
        "        self.linear_prev = nn.Linear(in_feats, out_feats)\n",
        "        self.linear_deg = nn.Linear(in_feats, out_feats)\n",
        "        self.linear_radius = nn.ModuleList(\n",
        "                [nn.Linear(in_feats, out_feats) for i in range(radius)])\n",
        "        self.linear_fuse = nn.Linear(in_feats, out_feats)\n",
        "        self.bn = nn.BatchNorm1d(out_feats)\n",
        "\n",
        "    def forward(self, g, feat_a, feat_b, deg, pm_pd):\n",
        "        # term \"prev\"\n",
        "        prev_proj = self.linear_prev(feat_a)\n",
        "        # term \"deg\"\n",
        "        deg_proj = self.linear_deg(deg * feat_a)\n",
        "\n",
        "        # term \"radius\"\n",
        "        # aggregate 2^j-hop features\n",
        "        hop2j_list = aggregate_radius(self.radius, g, feat_a)\n",
        "        # apply linear transformation\n",
        "        hop2j_list = [linear(x) for linear, x in zip(self.linear_radius, hop2j_list)]\n",
        "        radius_proj = sum(hop2j_list)\n",
        "\n",
        "        # term \"fuse\"\n",
        "        fuse = self.linear_fuse(th.mm(pm_pd, feat_b))\n",
        "\n",
        "        # sum them together\n",
        "        result = prev_proj + deg_proj + radius_proj + fuse\n",
        "\n",
        "        # skip connection and batch norm\n",
        "        n = self.out_feats // 2\n",
        "        result = th.cat([result[:, :n], F.relu(result[:, n:])], 1)\n",
        "        result = self.bn(result)\n",
        "\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LGNNLayer(nn.Module):\n",
        "    def __init__(self, in_feats, out_feats, radius):\n",
        "        super(LGNNLayer, self).__init__()\n",
        "        self.g_layer = LGNNCore(in_feats, out_feats, radius)\n",
        "        self.lg_layer = LGNNCore(in_feats, out_feats, radius)\n",
        "\n",
        "    def forward(self, g, lg, x, lg_x, deg_g, deg_lg, pm_pd):\n",
        "        next_x = self.g_layer(g, x, lg_x, deg_g, pm_pd)\n",
        "        pm_pd_y = th.transpose(pm_pd, 0, 1)\n",
        "        next_lg_x = self.lg_layer(lg, lg_x, x, deg_lg, pm_pd_y)\n",
        "        return next_x, next_lg_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LGNN(nn.Module):\n",
        "    def __init__(self, radius):\n",
        "        super(LGNN, self).__init__()\n",
        "        self.layer1 = LGNNLayer(1, 16, radius)  # input is scalar feature\n",
        "        self.layer2 = LGNNLayer(16, 16, radius)  # hidden size is 16\n",
        "        self.layer3 = LGNNLayer(16, 16, radius)\n",
        "        self.linear = nn.Linear(16, 7)  # predice seven classes\n",
        "\n",
        "    def forward(self, g, lg, pm_pd):\n",
        "        # compute the degrees\n",
        "        deg_g = g.in_degrees().float().unsqueeze(1)\n",
        "        deg_lg = lg.in_degrees().float().unsqueeze(1)\n",
        "        # use degree as the input feature\n",
        "        x, lg_x = deg_g, deg_lg\n",
        "        x, lg_x = self.layer1(g, lg, x, lg_x, deg_g, deg_lg, pm_pd)\n",
        "        x, lg_x = self.layer2(g, lg, x, lg_x, deg_g, deg_lg, pm_pd)\n",
        "        x, lg_x = self.layer3(g, lg, x, lg_x, deg_g, deg_lg, pm_pd)\n",
        "        return self.linear(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Loading CORA\n",
        "data = citegrh.load_cora()\n",
        "features = th.FloatTensor(data.features)\n",
        "labels = th.LongTensor(data.labels)\n",
        "mask = th.ByteTensor(data.train_mask)\n",
        "g = data.graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "<2708x10556 sparse matrix of type '<class 'numpy.int64'>'\n\twith 10556 stored elements in COOrdinate format>"
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matrix = lil_matrix((data.graph.number_of_nodes(),data.graph.number_of_edges()))\n",
        "for e in data.graph.edges:\n",
        "    matrix[e[0],e[1]] = 1\n",
        "inputs_pmpd = ss.coo_matrix(matrix,dtype=\"int64\")\n",
        "inputs_pmpd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "g = DGLGraph(g) # turn networkx graph into DGL graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "We have 2708 nodes.\nWe have 10556 edges.\n"
        }
      ],
      "source": [
        "print('We have %d nodes.' % g.number_of_nodes())\n",
        "print('We have %d edges.' % g.number_of_edges())"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Select Training Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "percentage_train = 0.02\n",
        "\n",
        "with open(\"data/cora_permutation1.pickle\",\"rb\") as f:\n",
        "    perm1 = pickle.load(f)\n",
        "mask = np.zeros(g.number_of_nodes())\n",
        "mask[perm1[range(int(percentage_train*g.number_of_nodes()))]] = 1\n",
        "mask = th.ByteTensor(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Epoch 0 | Loss: 1.9922 | Total: 274970443776.0000\nEpoch 1 | Loss: 1.8936 | Total: 7.5828\nEpoch 2 | Loss: 1.7970 | Total: 1.9283\nEpoch 3 | Loss: 1.7094 | Total: 1.8867\nEpoch 4 | Loss: 1.6568 | Total: 1.8358\nEpoch 5 | Loss: 1.6377 | Total: 93.5670\nEpoch 6 | Loss: 1.5826 | Total: 14.2129\nEpoch 7 | Loss: 1.5720 | Total: 3.4183\nEpoch 8 | Loss: 1.5470 | Total: 1.7551\nEpoch 9 | Loss: 1.5259 | Total: 1.7038\nEpoch 10 | Loss: 1.5019 | Total: 1.7021\nEpoch 11 | Loss: 1.4786 | Total: 1.7034\nEpoch 12 | Loss: 1.5199 | Total: 1.6926\nEpoch 13 | Loss: 1.4528 | Total: 1.6937\nEpoch 14 | Loss: 1.4353 | Total: 1.6920\nEpoch 15 | Loss: 1.4235 | Total: 1.6880\nEpoch 16 | Loss: 1.4099 | Total: 1.6841\nEpoch 17 | Loss: 1.4002 | Total: 1.6812\nEpoch 18 | Loss: 1.3887 | Total: 1.6744\nEpoch 19 | Loss: 1.3782 | Total: 1.6710\nEpoch 20 | Loss: 1.3683 | Total: 1.6723\nEpoch 21 | Loss: 1.3572 | Total: 1.6698\nEpoch 22 | Loss: 1.3458 | Total: 1.6751\nEpoch 23 | Loss: 1.3348 | Total: 1.6823\nEpoch 24 | Loss: 1.3216 | Total: 1.6943\nEpoch 25 | Loss: 1.3097 | Total: 1.7005\nEpoch 26 | Loss: 1.2935 | Total: 1.7135\nEpoch 27 | Loss: 1.2848 | Total: 1.7540\nEpoch 28 | Loss: 1.2698 | Total: 1.8241\nEpoch 29 | Loss: 1.2559 | Total: 1.9046\nEpoch 30 | Loss: 1.2411 | Total: 1.9571\nEpoch 31 | Loss: 1.2370 | Total: 1.9845\nEpoch 32 | Loss: 1.2240 | Total: 2.0056\nEpoch 33 | Loss: 1.2102 | Total: 2.0368\nEpoch 34 | Loss: 1.2034 | Total: 2.0793\nEpoch 35 | Loss: 1.1995 | Total: 2.0528\nEpoch 36 | Loss: 1.1779 | Total: 2.0824\nEpoch 37 | Loss: 1.1427 | Total: 2.1590\nEpoch 38 | Loss: 1.1247 | Total: 2.1403\nEpoch 39 | Loss: 1.1041 | Total: 2.0810\nEpoch 40 | Loss: 1.0944 | Total: 2.0153\nEpoch 41 | Loss: 1.0798 | Total: 1.8975\nEpoch 42 | Loss: 1.0955 | Total: 1.8676\nEpoch 43 | Loss: 1.0541 | Total: 1.8525\nEpoch 44 | Loss: 1.0907 | Total: 2.4712\nEpoch 45 | Loss: 1.0815 | Total: 2.0283\nEpoch 46 | Loss: 1.0718 | Total: 1.8840\nEpoch 47 | Loss: 1.0551 | Total: 1.8546\nEpoch 48 | Loss: 1.0417 | Total: 1.8352\nEpoch 49 | Loss: 1.0379 | Total: 1.8102\nEpoch 50 | Loss: 1.0248 | Total: 1.8240\nEpoch 51 | Loss: 1.0349 | Total: 1.8621\nEpoch 52 | Loss: 1.0106 | Total: 1.8735\nEpoch 53 | Loss: 1.0117 | Total: 1.9032\nEpoch 54 | Loss: 1.0019 | Total: 1.9237\nEpoch 55 | Loss: 0.9934 | Total: 1.9283\nEpoch 56 | Loss: 0.9855 | Total: 1.8412\nEpoch 57 | Loss: 0.9732 | Total: 1.8147\nEpoch 58 | Loss: 0.9669 | Total: 1.8062\nEpoch 59 | Loss: 0.9589 | Total: 1.7975\nEpoch 60 | Loss: 0.9544 | Total: 1.7885\nEpoch 61 | Loss: 0.9473 | Total: 1.7876\nEpoch 62 | Loss: 0.9434 | Total: 1.7907\nEpoch 63 | Loss: 0.9337 | Total: 1.7893\nEpoch 64 | Loss: 0.9258 | Total: 1.7810\nEpoch 65 | Loss: 1.1420 | Total: 1.7967\nEpoch 66 | Loss: 0.9161 | Total: 1.7821\nEpoch 67 | Loss: 0.9162 | Total: 1.7871\nEpoch 68 | Loss: 0.8996 | Total: 1.7918\nEpoch 69 | Loss: 0.9013 | Total: 1.7994\nEpoch 70 | Loss: 0.8875 | Total: 1.8059\nEpoch 71 | Loss: 0.8794 | Total: 1.8109\nEpoch 72 | Loss: 0.9307 | Total: 1.8185\nEpoch 73 | Loss: 0.9170 | Total: 1.8215\nEpoch 74 | Loss: 0.8746 | Total: 1.8165\nEpoch 75 | Loss: 0.8847 | Total: 1.8133\nEpoch 76 | Loss: 0.8741 | Total: 1.8107\nEpoch 77 | Loss: 0.8702 | Total: 1.8181\nEpoch 78 | Loss: 0.8594 | Total: 1.8375\nEpoch 79 | Loss: 0.8566 | Total: 1.8605\nEpoch 80 | Loss: 0.8478 | Total: 1.8817\nEpoch 81 | Loss: 0.8241 | Total: 1.9100\nEpoch 82 | Loss: 0.8109 | Total: 1.9296\nEpoch 83 | Loss: 0.8045 | Total: 1.9611\nEpoch 84 | Loss: 0.7944 | Total: 1.9803\nEpoch 85 | Loss: 0.8380 | Total: 2.0054\nEpoch 86 | Loss: 0.7885 | Total: 2.0808\nEpoch 87 | Loss: 0.8162 | Total: 2.2059\nEpoch 88 | Loss: 0.8510 | Total: 2.1429\nEpoch 89 | Loss: 0.8473 | Total: 2.1552\nEpoch 90 | Loss: 0.8294 | Total: 2.1701\nEpoch 91 | Loss: 0.8270 | Total: 2.2249\nEpoch 92 | Loss: 0.8501 | Total: 2.3621\nEpoch 93 | Loss: 0.8665 | Total: 2.3965\nEpoch 94 | Loss: 0.8301 | Total: 2.3197\nEpoch 95 | Loss: 0.8019 | Total: 2.2062\nEpoch 96 | Loss: 0.7784 | Total: 2.1084\nEpoch 97 | Loss: 0.7660 | Total: 2.0644\nEpoch 98 | Loss: 0.7614 | Total: 2.0464\nEpoch 99 | Loss: 0.7575 | Total: 2.0429\n"
        }
      ],
      "source": [
        "# create the model\n",
        "net = LGNN(radius=3)\n",
        "# define the optimizer\n",
        "optimizer = th.optim.Adam(net.parameters(), lr=1e-2)\n",
        "\n",
        "# a util function to convert a scipy.coo_matrix to torch.SparseFloat\n",
        "def sparse2th(mat):\n",
        "    value = mat.data\n",
        "    indices = th.LongTensor([mat.row, mat.col])\n",
        "    tensor = th.sparse.FloatTensor(indices, th.from_numpy(value).float(), mat.shape)\n",
        "    return tensor\n",
        "\n",
        "all_logits = []\n",
        "\n",
        "pmpd = sparse2th(inputs_pmpd)\n",
        "lg = g.line_graph(backtracking=False)\n",
        "\n",
        "# train\n",
        "for epoch in range(100):\n",
        "\n",
        "    # Compute loss for test nodes (only for validation, not used by optimizer)\n",
        "    net.eval()\n",
        "    prediction = F.log_softmax(net(g, lg, pmpd),1)\n",
        "    val_loss = F.nll_loss(prediction.detach()[1-mask], labels[1-mask])\n",
        "    net.train()\n",
        "\n",
        "    logits = net(g, lg, pmpd)\n",
        "    # Save logits for visualization later\n",
        "    all_logits.append(logits.detach())\n",
        "    logp = F.log_softmax(logits, 1)\n",
        "\n",
        "    # Compute loss for train nodes\n",
        "    loss = F.nll_loss(logp[mask], labels[mask])\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    print('Epoch %d | Loss: %.4f | Total: %.4f' % (epoch, loss.item(), val_loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\nNLL-Loss:\n All : 1.9709 | Train: 0.9894 | Test: 1.9909 |\n\nAccuracy:\n All : 0.4140 | Train: 0.6111 | Test: 0.4099 |\n"
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score as acc\n",
        "net.eval() # Set net to evaluation mode (deactivates dropout)\n",
        "final_prediction = F.log_softmax(net(g, lg, pmpd),1).detach()\n",
        "\n",
        "pred_sets = {\"All \":final_prediction,\"Train\":final_prediction[mask],\"Test\":final_prediction[1-mask]}\n",
        "label_sets = {\"All \":labels,\"Train\":labels[mask],\"Test\":labels[1-mask]}\n",
        "eval_functions = {\"NLL-Loss\":lambda y,x: F.nll_loss(x,y),\"Accuracy\":lambda y,x: acc(y,x.numpy().argmax(axis=1))}\n",
        "\n",
        "for name,func in eval_functions.items():\n",
        "    eval_message = f\"\\n{name}:\\n\"\n",
        "    for subset in pred_sets.keys():\n",
        "        eval_message += f\" {subset}: {func(label_sets[subset],pred_sets[subset]):.4f} |\"\n",
        "    print(eval_message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}